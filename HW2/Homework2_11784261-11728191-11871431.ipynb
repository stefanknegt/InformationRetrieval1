{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval 1#\n",
    "## Assignment 2: Retrieval models [100 points] ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will get familiar with basic and advanced information retrieval concepts. You will implement different information retrieval ranking models and evaluate their performance.\n",
    "\n",
    "We provide you with a Indri index. To query the index, you'll use a Python package ([pyndri](https://github.com/cvangysel/pyndri)) that allows easy access to the underlying document statistics.\n",
    "\n",
    "For evaluation you'll use the [TREC Eval](https://github.com/usnistgov/trec_eval) utility, provided by the National Institute of Standards and Technology of the United States. TREC Eval is the de facto standard way to compute Information Retrieval measures and is frequently referenced in scientific papers.\n",
    "\n",
    "This is a **groups-of-three assignment**, the deadline is **Wednesday, January 31st**. Code quality, informative comments and convincing analysis of the results will be considered when grading. Submission should be done through blackboard, questions can be asked on the course [Piazza](piazza.com/university_of_amsterdam/spring2018/52041inr6y/home).\n",
    "\n",
    "### Technicalities (must-read!) ###\n",
    "\n",
    "The assignment directory is organized as follows:\n",
    "   * `./assignment.ipynb` (this file): the description of the assignment.\n",
    "   * `./index/`: the index we prepared for you.\n",
    "   * `./ap_88_90/`: directory with ground-truth and evaluation sets:\n",
    "      * `qrel_test`: test query relevance collection (**test set**).\n",
    "      * `qrel_validation`: validation query relevance collection (**validation set**).\n",
    "      * `topics_title`: semicolon-separated file with query identifiers and terms.\n",
    "\n",
    "You will need the following software packages (tested with Python 3.5 inside [Anaconda](https://conda.io/docs/user-guide/install/index.html)):\n",
    "   * Python 3.5 and Jupyter\n",
    "   * Indri + Pyndri (Follow the installation instructions [here](https://github.com/nickvosk/pyndri/blob/master/README.md))\n",
    "   * gensim [link](https://radimrehurek.com/gensim/install.html)\n",
    "   * TREC Eval [link](https://github.com/usnistgov/trec_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TREC Eval primer ###\n",
    "The TREC Eval utility can be downloaded and compiled as follows:\n",
    "\n",
    "    git clone https://github.com/usnistgov/trec_eval.git\n",
    "    cd trec_eval\n",
    "    make\n",
    "\n",
    "TREC Eval computes evaluation scores given two files: ground-truth information regarding relevant documents, named *query relevance* or *qrel*, and a ranking of documents for a set of queries, referred to as a *run*. The *qrel* will be supplied by us and should not be changed. For every retrieval model (or combinations thereof) you will generate a run of the top-1000 documents for every query. The format of the *run* file is as follows:\n",
    "\n",
    "    $query_identifier Q0 $document_identifier $rank_of_document_for_query $query_document_similarity $run_identifier\n",
    "    \n",
    "where\n",
    "   * `$query_identifier` is the unique identifier corresponding to a query (usually this follows a sequential numbering).\n",
    "   * `Q0` is a legacy field that you can ignore.\n",
    "   * `$document_identifier` corresponds to the unique identifier of a document (e.g., APXXXXXXX where AP denotes the collection and the Xs correspond to a unique numerical identifier).\n",
    "   * `$rank_of_document_for_query` denotes the rank of the document for the particular query. This field is ignored by TREC Eval and is only maintained for legacy support. The ranks are computed by TREC Eval itself using the `$query_document_similarity` field (see next). However, it remains good practice to correctly compute this field.\n",
    "   * `$query_document_similarity` is a score indicating the similarity between query and document where a higher score denotes greater similarity.\n",
    "   * `$run_identifier` is an identifier of the run. This field is for your own convenience and has no purpose beyond bookkeeping.\n",
    "   \n",
    "For example, say we have two queries: `Q1` and `Q2` and we rank three documents (`DOC1`, `DOC2`, `DOC3`). For query `Q1`, we find the following similarity scores `score(Q1, DOC1) = 1.0`, `score(Q1, DOC2) = 0.5`, `score(Q1, DOC3) = 0.75`; and for `Q2`: `score(Q2, DOC1) = -0.1`, `score(Q2, DOC2) = 1.25`, `score(Q1, DOC3) = 0.0`. We can generate run using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 Q0 DOC1 1 1.0 example\n",
      "Q1 Q0 DOC3 2 0.75 example\n",
      "Q1 Q0 DOC2 3 0.5 example\n",
      "Q2 Q0 DOC2 1 1.25 example\n",
      "Q2 Q0 DOC3 2 0.0 example\n",
      "Q2 Q0 DOC1 3 -0.1 example\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def write_run(model_name, data, out_f,\n",
    "              max_objects_per_query=sys.maxsize,\n",
    "              skip_sorting=False):\n",
    "    \"\"\"\n",
    "    Write a run to an output file.\n",
    "    Parameters:\n",
    "        - model_name: identifier of run.\n",
    "        - data: dictionary mapping topic_id to object_assesments;\n",
    "            object_assesments is an iterable (list or tuple) of\n",
    "            (relevance, object_id) pairs.\n",
    "            The object_assesments iterable is sorted by decreasing order.\n",
    "        - out_f: output file stream.\n",
    "        - max_objects_per_query: cut-off for number of objects per query.\n",
    "    \"\"\"\n",
    "    for subject_id, object_assesments in data.items():\n",
    "        if not object_assesments:\n",
    "            logging.warning('Received empty ranking for %s; ignoring.',\n",
    "                            subject_id)\n",
    "\n",
    "            continue\n",
    "\n",
    "        #Probe types, to make sure everything goes alright.\n",
    "        assert isinstance(object_assesments[0][0], float) or \\\n",
    "             isinstance(object_assesments[0][0], np.float32)\n",
    "        assert isinstance(object_assesments[0][1], str) or \\\n",
    "            isinstance(object_assesments[0][1], bytes)\n",
    "\n",
    "        if not skip_sorting:\n",
    "            object_assesments = sorted(object_assesments, reverse=True)\n",
    "\n",
    "        if max_objects_per_query < sys.maxsize:\n",
    "            object_assesments = object_assesments[:max_objects_per_query]\n",
    "\n",
    "        if isinstance(subject_id, bytes):\n",
    "            subject_id = subject_id.decode('utf8')\n",
    "\n",
    "        for rank, (relevance, object_id) in enumerate(object_assesments):\n",
    "            if isinstance(object_id, bytes):\n",
    "                object_id = object_id.decode('utf8')\n",
    "\n",
    "            out_f.write(\n",
    "                '{subject} Q0 {object} {rank} {relevance} '\n",
    "                '{model_name}\\n'.format(\n",
    "                    subject=subject_id,\n",
    "                    object=object_id,\n",
    "                    rank=rank + 1,\n",
    "                    relevance=relevance,\n",
    "                    model_name=model_name))\n",
    "            \n",
    "# The following writes the run to standard output.\n",
    "# In your code, you should write the runs to local\n",
    "# storage in order to pass them to trec_eval.\n",
    "write_run(\n",
    "    model_name='example',\n",
    "    data={\n",
    "        'Q1': ((1.0, 'DOC1'), (0.5, 'DOC2'), (0.75, 'DOC3')),\n",
    "        'Q2': ((-0.1, 'DOC1'), (1.25, 'DOC2'), (0.0, 'DOC3')),\n",
    "    },\n",
    "    out_f=sys.stdout,\n",
    "    max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine that we know that `DOC1` is relevant and `DOC3` is non-relevant for `Q1`. In addition, for `Q2` we only know of the relevance of `DOC3`. The query relevance file looks like:\n",
    "\n",
    "    Q1 0 DOC1 1\n",
    "    Q1 0 DOC3 0\n",
    "    Q2 0 DOC3 1\n",
    "    \n",
    "We store the run and qrel in files `example.run` and `example.qrel` respectively on disk. We can now use TREC Eval to compute evaluation measures. In this example, we're only interested in Mean Average Precision and we'll only show this below for brevity. However, TREC Eval outputs much more information such as NDCG, recall, precision, etc.\n",
    "\n",
    "    $ trec_eval -m all_trec -q example.qrel example.run | grep -E \"^map\\s\"\n",
    "    > map                   \tQ1\t1.0000\n",
    "    > map                   \tQ2\t0.5000\n",
    "    > map                   \tall\t0.7500\n",
    "    \n",
    "Now that we've discussed the output format of rankings and how you can compute evaluation measures from these rankings, we'll now proceed with an overview of the indexing framework you'll use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyndri primer ###\n",
    "For this assignment you will use [Pyndri](https://github.com/cvangysel/pyndri) [[1](https://arxiv.org/abs/1701.00749)], a python interface for [Indri](https://www.lemurproject.org/indri.php). We have indexed the document collection and you can query the index using Pyndri. We will start by giving you some examples of what Pyndri can do:\n",
    "\n",
    "First we read the document collection index with Pyndri:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyndri\n",
    "\n",
    "index = pyndri.Index('index/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded index can be used to access a collection of documents in an easy manner. We'll give you some examples to get some idea of what it can do, it is up to you to figure out how to use it for the remainder of the assignment.\n",
    "\n",
    "First let's look at the number of documents, since Pyndri indexes the documents using incremental identifiers we can simply take the lowest index and the maximum document and consider the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 164597 documents in this collection.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d documents in this collection.\" % (index.maximum_document() - index.document_base()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the first document out of the collection and take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AP890425-0001', (1360, 192, 363, 0, 880, 0, 200, 0, 894, 412, 92160, 3, 192, 0, 363, 34, 1441, 0, 174134, 0, 200, 0, 894, 412, 2652, 0, 810, 107, 49, 4903, 420, 0, 1, 48, 35, 489, 0, 35, 687, 192, 243, 0, 249311, 1877, 0, 1651, 1174, 0, 2701, 117, 412, 0, 810, 391, 245233, 1225, 5838, 16, 0, 233156, 3496, 0, 393, 17, 0, 2435, 4819, 930, 0, 0, 200, 0, 894, 0, 22, 398, 145, 0, 3, 271, 115, 0, 1176, 2777, 292, 0, 725, 192, 0, 0, 50046, 0, 1901, 1130, 0, 192, 0, 408, 0, 243779, 0, 0, 553, 192, 0, 363, 0, 3747, 0, 0, 0, 0, 1176, 0, 1239, 0, 0, 1115, 17, 0, 0, 585, 192, 1963, 0, 0, 412, 54356, 0, 773, 0, 0, 0, 192, 0, 0, 1130, 0, 363, 0, 545, 192, 0, 1174, 1901, 1130, 0, 4, 398, 145, 39, 0, 577, 0, 355, 0, 491, 0, 6025, 0, 0, 193156, 88, 34, 437, 0, 0, 1852, 0, 828, 0, 1588, 0, 0, 0, 2615, 0, 0, 107, 49, 420, 0, 0, 190, 7, 714, 2701, 0, 237, 192, 157, 0, 412, 34, 437, 0, 0, 200, 6025, 26, 0, 0, 0, 0, 363, 0, 22, 398, 145, 0, 200, 638, 126222, 6018, 0, 880, 0, 0, 161, 0, 0, 319, 894, 2701, 0, 0, 0, 301, 1200, 0, 363, 251, 430, 0, 207, 0, 76143, 1773, 0, 243779, 0, 0, 72030, 0, 55, 4903, 420, 0, 2701, 1496, 420, 0, 25480, 0, 420, 0, 0, 200, 0, 392, 2949, 0, 1738, 0, 61, 0, 71, 79, 0, 200, 903, 0, 188, 53, 6, 0, 476, 2, 0, 2028, 97, 334, 0, 0, 200, 178, 0, 0, 107, 49, 0, 214, 0, 0, 0, 114, 3866, 1505, 195, 79893, 574, 0, 198, 2160, 0, 192, 0, 420, 0, 384, 0, 2701, 0, 114, 6025, 1549, 74627, 0, 238, 0, 0, 0, 3729, 0, 192, 0, 79893, 0, 0, 729, 3141, 129, 0, 192, 196764, 39, 0, 0, 714, 63, 0, 55, 420, 3356, 0, 0, 117, 412, 0, 0, 79758, 0, 1901, 1130, 4067, 2133, 0, 0, 875, 72, 0, 0, 336, 2789, 0, 0, 25, 920, 121, 104, 0, 3162, 0, 0, 420, 0, 2178, 0, 0, 386, 192545, 159306, 0, 0, 0, 1914, 0, 200, 0, 1794, 0, 2654, 0, 0, 25480, 420, 0, 2795, 0, 0, 229690, 0, 32559, 0, 0, 392, 253919, 0, 0, 0, 0, 379, 0, 0, 114, 0, 553, 10, 0, 1128, 0, 23610, 248, 151, 0, 418, 0, 651, 0, 36, 0, 0, 645, 0, 0, 513, 0, 0, 25480, 420, 34, 0, 0, 0, 15, 0, 3348, 0, 3496, 0, 35, 687, 0, 1, 48, 0, 0, 2803, 0, 0, 714, 1274, 0, 114, 62, 1006, 70268, 1200, 2357, 0, 497, 0, 497, 125, 0, 913, 4647, 3985, 0, 0, 3370, 245233, 0, 0, 687, 0, 4, 1288, 0, 0, 0, 0, 715, 0, 0, 687, 583, 0, 0, 1627, 0, 0, 11, 357, 1359, 0, 849, 0, 0, 1518, 462, 245233, 0, 0, 0, 0, 0, 0, 171, 70268, 0))\n"
     ]
    }
   ],
   "source": [
    "example_document = index.document(index.document_base())\n",
    "print(example_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a document consists of two things, a string representing the external document identifier and an integer list representing the identifiers of words that make up the document. Pyndri uses integer representations for words or terms, thus a token_id is an integer that represents a word whereas the token is the actual text of the word/term. Every id has a unique token and vice versa with the exception of stop words: words so common that there are uninformative, all of these receive the zero id.\n",
    "\n",
    "To see what some ids and their matching tokens we take a look at the dictionary of the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'new'), (2, 'percent'), (3, 'two'), (4, '1'), (5, 'people'), (6, 'million'), (7, '000'), (8, 'government'), (9, 'president'), (10, 'years'), (11, 'state'), (12, '2'), (13, 'states'), (14, 'three'), (15, 'time')]\n"
     ]
    }
   ],
   "source": [
    "token2id, id2token, _ = index.get_dictionary()\n",
    "print(list(id2token.items())[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this dictionary we can see the tokens for the (non-stop) words in our example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['52', 'students', 'arrested', 'takeover', 'university', 'massachusetts', 'building', 'fifty', 'two', 'students', 'arrested', 'tuesday', 'evening', 'occupying', 'university', 'massachusetts', 'building', 'overnight', 'protest', 'defense', 'department', 'funded', 'research', 'new', 'york', 'city', 'thousands', 'city', 'college', 'students', 'got', 'unscheduled', 'holiday', 'demonstrators', 'occupied', 'campus', 'administration', 'building', 'protest', 'possible', 'tuition', 'increases', 'prompting', 'officials', 'suspend', 'classes', '60', 'police', 'riot', 'gear', 'arrived', 'university', 'massachusetts', '5', 'p', 'm', 'two', 'hours', 'later', 'bus', 'drove', 'away', '29', 'students', 'camped', 'memorial', 'hall', 'students', 'charged', 'trespassing', '23', 'students', 'arrested', 'lying', 'bus', 'prevent', 'leaving', 'police', '300', 'students', 'stood', 'building', 'chanting', 'looking', 'students', 'hall', 'arrested', '35', 'students', 'occupied', 'memorial', 'hall', '1', 'p', 'm', 'monday', 'declined', 'offer', 'meet', 'administrators', 'provosts', 'office', 'tuesday', 'morning', 'presented', 'list', 'demands', 'halt', 'defense', 'department', 'research', '25', '000', 'student', 'campus', '40', 'students', 'left', 'building', 'tuesday', 'morning', 'university', 'administrators', 'told', 'arrested', '5', 'p', 'm', 'university', 'spokeswoman', 'jeanne', 'hopkins', 'takeover', 'second', 'western', 'massachusetts', 'campus', 'seven', 'protesters', 'arrested', 'april', '19', 'charges', 'disorderly', 'conduct', 'trespassing', 'demonstrating', 'military', 'funded', 'research', 'campus', 'particularly', 'research', 'anthrax', 'research', 'university', 'non', 'classified', 'researchers', 'make', 'work', 'public', 'university', 'rules', '11', '6', 'million', '22', 'percent', 'grant', 'money', 'received', 'university', 'came', 'defense', 'department', '1988', 'school', 'chancellor', 'joseph', 'd', 'duffey', 'issued', 'statement', 'telling', 'students', 'research', 'continue', 'campus', 'school', 'administrators', 'decide', 'differently', 'policy', 'negotiated', 'students', 'duffey', 'latest', 'occupation', 'began', 'students', 'rallying', 'monday', 'student', 'union', 'military', 'research', 'marched', 'administration', 'building', 'ducked', 'memorial', 'hall', 'en', 'route', 'followed', 'members', 'local', 'chapter', 'american', 'friends', 'service', 'committee', 'contended', 'research', 'dangerous', 'town', 'promotes', 'militarism', 'banned', 'university', 'argued', 'purpose', 'anthrax', 'research', 'peaceful', 'strain', 'bacteria', 'non', 'virulent', 'study', 'school', '23', 'years', 'incident', 'amherst', 'health', 'board', 'scheduled', 'hearing', 'wednesday', 'question', 'safety', 'anthrax', 'research', 'tuesday', 'time', '1969', 'classes', 'city', 'college', 'new', 'york', 'canceled', 'student', 'protests', 'school', 'spokesman', 'charles', 'deciccio', 'protesters', 'demanding', 'face', 'face', 'meeting', 'gov', 'mario', 'cuomo', 'feared', 'tuition', 'college', '1', '250', 'increased', 'college', 'staff', 'reduced', 'state', 'budget', 'cuts', 'governor', 'immediate', 'comment', 'tuition', 'set', 'deciccio']\n"
     ]
    }
   ],
   "source": [
    "print([id2token[word_id] for word_id in example_document[1] if word_id > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reverse can also be done, say we want to look for news about the \"University of Massachusetts\", the tokens of that query can be converted to ids using the reverse dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query by tokens: ['university', '', 'massachusetts']\n",
      "Query by ids with stopwords: [200, 0, 894]\n",
      "Query by ids without stopwords: [200, 894]\n"
     ]
    }
   ],
   "source": [
    "query_tokens = index.tokenize(\"University of Massachusetts\")\n",
    "print(\"Query by tokens:\", query_tokens)\n",
    "query_id_tokens = [token2id.get(query_token,0) for query_token in query_tokens]\n",
    "print(\"Query by ids with stopwords:\", query_id_tokens)\n",
    "query_id_tokens = [word_id for word_id in query_id_tokens if word_id > 0]\n",
    "print(\"Query by ids without stopwords:\", query_id_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally we can now match the document and query in the id space, let's see how often a word from the query occurs in our example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document AP890425-0001 has 13 word matches with query: \"university  massachusetts\".\n",
      "Document AP890425-0001 and query \"university  massachusetts\" have a 2.5% overlap.\n"
     ]
    }
   ],
   "source": [
    "matching_words = sum([True for word_id in example_document[1] if word_id in query_id_tokens])\n",
    "print(\"Document %s has %d word matches with query: \\\"%s\\\".\" % (example_document[0], matching_words, ' '.join(query_tokens)))\n",
    "print(\"Document %s and query \\\"%s\\\" have a %.01f%% overlap.\" % (example_document[0], ' '.join(query_tokens),matching_words/float(len(example_document[1]))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is certainly not everything Pyndri can do, it should give you an idea of how to use it. Please take a look at the [examples](https://github.com/cvangysel/pyndri) as it will help you a lot with this assignment.\n",
    "\n",
    "**CAUTION**: Avoid printing out the whole index in this Notebook as it will generate a lot of output and is likely to corrupt the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the query file\n",
    "You can parse the query file (`ap_88_89/topics_title`) using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('51', 'Airbus Subsidies'), ('52', 'South African Sanctions'), ('53', 'Leveraged Buyouts'), ('54', 'Satellite Launch Contracts'), ('55', 'Insider Trading'), ('56', 'Prime (Lending) Rate Moves, Predictions'), ('57', 'MCI'), ('58', 'Rail Strikes'), ('59', 'Weather Related Fatalities'), ('60', 'Merit-Pay vs. Seniority'), ('61', 'Israeli Role in Iran-Contra Affair'), ('62', \"Military Coups D'etat\"), ('63', 'Machine Translation'), ('64', 'Hostage-Taking'), ('65', 'Information Retrieval Systems'), ('66', 'Natural Language Processing'), ('67', 'Politically Motivated Civil Disturbances'), ('68', 'Health Hazards from Fine-Diameter Fibers'), ('69', 'Attempts to Revive the SALT II Treaty'), ('70', 'Surrogate Motherhood'), ('71', 'Border Incursions'), ('72', 'Demographic Shifts in the U.S.'), ('73', 'Demographic Shifts across National Boundaries'), ('74', 'Conflicting Policy'), ('75', 'Automation'), ('76', 'U.S. Constitution - Original Intent'), ('77', 'Poaching'), ('78', 'Greenpeace'), ('79', 'FRG Political Party Positions'), ('80', '1988 Presidential Candidates Platforms'), ('81', 'Financial crunch for televangelists in the wake of the PTL scandal'), ('82', 'Genetic Engineering'), ('83', 'Measures to Protect the Atmosphere'), ('84', 'Alternative/renewable Energy Plant & Equipment Installation'), ('85', 'Official Corruption'), ('86', 'Bank Failures'), ('87', 'Criminal Actions Against Officers of Failed Financial Institutions'), ('88', 'Crude Oil Price Trends'), ('89', '\"Downstream\" Investments by OPEC Member States'), ('90', 'Data on Proven Reserves of Oil & Natural Gas Producers'), ('91', 'U.S. Army Acquisition of Advanced Weapons Systems'), ('92', 'International Military Equipment Sales'), ('93', 'What Backing Does the National Rifle Association Have?'), ('94', 'Computer-aided Crime'), ('95', 'Computer-aided Crime Detection'), ('96', 'Computer-Aided Medical Diagnosis'), ('97', 'Fiber Optics Applications'), ('98', 'Fiber Optics Equipment Manufacturers'), ('99', 'Iran-Contra Affair'), ('100', 'Controlling the Transfer of High Technology'), ('101', 'Design of the \"Star Wars\" Anti-missile Defense System'), ('102', \"Laser Research Applicable to the U.S.'s Strategic Defense Initiative\"), ('103', 'Welfare Reform'), ('104', 'Catastrophic Health Insurance'), ('105', '\"Black Monday\"'), ('106', 'U.S. Control of Insider Trading'), ('107', 'Japanese Regulation of Insider Trading'), ('108', 'Japanese Protectionist Measures'), ('109', 'Find Innovative Companies'), ('110', 'Black Resistance Against the South African Government'), ('111', 'Nuclear Proliferation'), ('112', 'Funding Biotechnology'), ('113', 'New Space Satellite Applications'), ('114', 'Non-commercial Satellite Launches'), ('115', 'Impact of the 1986 Immigration Law'), ('116', 'Generic Drug Substitutions'), ('117', 'Capacity of the U.S. Cellular Telephone Network'), ('118', 'International Terrorists'), ('119', 'Actions Against International Terrorists'), ('120', 'Economic Impact of International Terrorism'), ('121', 'Death from Cancer'), ('122', 'RDT&E of New Cancer Fighting Drugs'), ('123', 'Research into & Control of Carcinogens'), ('124', 'Alternatives to Traditional Cancer Therapies'), ('125', 'Anti-smoking Actions by Government'), ('126', 'Medical Ethics and Modern Technology'), ('127', 'U.S.-U.S.S.R. Arms Control Agreements'), ('128', 'Privatization of State Assets'), ('129', 'Soviet Spying on the U.S.'), ('130', 'Jewish Emigration and U.S.-USSR Relations'), ('131', 'McDonnell Douglas Contracts for Military Aircraft'), ('132', '\"Stealth\" Aircraft'), ('133', 'Hubble Space Telescope'), ('134', 'The Human Genome Project'), ('135', 'Possible Contributions of Gene Mapping to Medicine'), ('136', 'Diversification by Pacific Telesis'), ('137', 'Expansion in the U.S. Theme Park Industry'), ('138', 'Iranian Support for Lebanese Hostage-takers'), ('139', \"Iran's Islamic Revolution - Domestic and Foreign Social Consequences\"), ('140', 'Political Impact of Islamic Fundamentalism'), ('141', \"Japan's Handling of its Trade Surplus with the U.S.\"), ('142', 'Impact of Government Regulated Grain Farming on International Relations'), ('143', 'Why Protect U.S. Farmers?'), ('144', 'Management Problems at the United Nations'), ('145', 'Influence of the \"Pro-Israel Lobby\"'), ('146', 'Negotiating an End to the Nicaraguan Civil War'), ('147', 'Productivity Trends in the U.S. Economy'), ('148', 'Conflict in the Horn of Africa'), ('149', 'Industrial Espionage'), ('150', 'U.S. Political Campaign Financing'), ('151', 'Coping with overcrowded prisons'), ('152', 'Accusations of Cheating by Contractors on U.S. Defense Projects'), ('153', 'Insurance Coverage which pays for Long Term Care'), ('154', 'Oil Spills'), ('155', 'Right Wing Christian Fundamentalism in U.S.'), ('156', 'Efforts to enact Gun Control Legislation'), ('157', 'Causes and treatments of multiple sclerosis (MS)'), ('158', 'Term limitations for members of the U.S. Congress'), ('159', 'Electric Car Development'), ('160', 'Vitamins - The Cure for or Cause of Human Ailments'), ('161', 'Acid Rain'), ('162', 'Automobile Recalls'), ('163', 'Vietnam Veterans and Agent Orange'), ('164', 'Generic Drugs - Illegal Activities by Manufacturers'), ('165', 'Tobacco company advertising and the young'), ('166', 'Standardized testing and cultural bias'), ('167', 'Regulation of the showing of violence and explicit sex in motion picture theaters, on television, and on video cassettes.'), ('168', 'Financing AMTRAK'), ('169', 'Cost of Garbage/Trash Removal'), ('170', 'The Consequences of Implantation of Silicone Gel Breast Devices'), ('171', \"Use of Mutual Funds in an Individual's Retirement Strategy\"), ('172', 'The Effectiveness of Medical Products and Related Programs Utilized in the Cessation of Smoking.'), ('173', 'Smoking Bans'), ('174', 'Hazardous Waste Cleanup'), ('175', 'NRA Prevention of Gun Control Legislation'), ('176', 'Real-life private investigators'), ('177', 'English as the Official Language in U.S.'), ('178', 'Dog Maulings'), ('179', 'U. S. Restaurants in Foreign Lands'), ('180', 'Ineffectiveness of U.S. Embargoes/Sanctions'), ('181', 'Abuse of the Elderly by Family Members, and Medical and Nonmedical Personnel, and Initiatives Being Taken to Minimize This Mistreatment'), ('182', 'Commercial Overfishing Creates Food Fish Deficit'), ('183', 'Asbestos Related Lawsuits'), ('184', 'Corporate Pension Plans/Funds'), ('185', 'Reform of the U.S. Welfare System'), ('186', 'Difference of Learning Levels Among Inner City and More Suburban School Students'), ('187', 'Signs of the Demise of Independent Publishing'), ('188', 'Beachfront Erosion'), ('189', 'Real Motives for Murder'), ('190', 'Instances of Fraud Involving the Use of a Computer'), ('191', 'Efforts to Improve U.S. Schooling'), ('192', 'Oil Spill Cleanup'), ('193', 'Toys R Dangerous'), ('194', 'The Amount of Money Earned by Writers'), ('195', 'Stock Market Perturbations Attributable to Computer Initiated Trading'), ('196', 'School Choice Voucher System and its effects upon the entire U.S. educational program'), ('197', 'Reform of the jurisprudence system to stop juries from granting unreasonable monetary awards'), ('198', 'Gene Therapy and Its Benefits to Humankind'), ('199', 'Legality of Medically Assisted Suicides'), ('200', 'Impact of foreign textile imports on U.S. textile industry')])\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import io\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def parse_topics(file_or_files,\n",
    "                 max_topics=sys.maxsize, delimiter=';'):\n",
    "    assert max_topics >= 0 or max_topics is None\n",
    "\n",
    "    topics = collections.OrderedDict()\n",
    "\n",
    "    if not isinstance(file_or_files, list) and \\\n",
    "            not isinstance(file_or_files, tuple):\n",
    "        if hasattr(file_or_files, '__iter__'):\n",
    "            file_or_files = list(file_or_files)\n",
    "        else:\n",
    "            file_or_files = [file_or_files]\n",
    "\n",
    "    for f in file_or_files:\n",
    "        assert isinstance(f, io.IOBase)\n",
    "\n",
    "        for line in f:\n",
    "            assert(isinstance(line, str))\n",
    "\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            topic_id, terms = line.split(delimiter, 1)\n",
    "\n",
    "            if topic_id in topics and (topics[topic_id] != terms):\n",
    "                    logging.error('Duplicate topic \"%s\" (%s vs. %s).',\n",
    "                                  topic_id,\n",
    "                                  topics[topic_id],\n",
    "                                  terms)\n",
    "\n",
    "            topics[topic_id] = terms\n",
    "\n",
    "            if max_topics > 0 and len(topics) >= max_topics:\n",
    "                break\n",
    "\n",
    "    return topics\n",
    "\n",
    "with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "    print(parse_topics([f_topics]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement and compare lexical IR methods [35 points] ### \n",
    "\n",
    "In this task you will implement a number of lexical methods for IR using the **Pyndri** framework. Then you will evaluate these methods on the dataset we have provided using **TREC Eval**.\n",
    "\n",
    "Use the **Pyndri** framework to get statistics of the documents (term frequency, document frequency, collection frequency; **you are not allowed to use the query functionality of Pyndri**) and implement the following scoring methods in **Python**:\n",
    "\n",
    "- [TF-IDF](http://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html) and \n",
    "- [BM25](http://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html) with k1=1.2 and b=0.75. **[5 points]**\n",
    "- Language models ([survey](https://drive.google.com/file/d/0B-zklbckv9CHc0c3b245UW90NE0/view))\n",
    "    - Jelinek-Mercer (explore different values of ð›Œ in the range [0.1, 0.5, 0.9]). **[5 points]**\n",
    "    - Dirichlet Prior (explore different values of ð› [500, 1000, 1500]). **[5 points]**\n",
    "    - Absolute discounting (explore different values of ð›… in the range [0.1, 0.5, 0.9]). **[5 points]**\n",
    "    - [Positional Language Models](http://sifaka.cs.uiuc.edu/~ylv2/pub/sigir09-plm.pdf) define a language model for each position of a document, and score a document based on the scores of its PLMs. The PLM is estimated based on propagated counts of words within a document through a proximity-based density function, which both captures proximity heuristics and achieves an effect of â€œsoftâ€ passage retrieval. Implement the PLM, all five kernels, but only the Best position strategy to score documents. Use ð›” equal to 50, and Dirichlet smoothing with ð› optimized on the validation set (decide how to optimize this value yourself and motivate your decision in the report). **[10 points]**\n",
    "    \n",
    "Implement the above methods and report evaluation measures (on the test set) using the hyper parameter values you optimized on the validation set (also report the values of the hyper parameters). Use TREC Eval to obtain the results and report on `NDCG@10`, Mean Average Precision (`MAP@1000`), `Precision@5` and `Recall@1000`.\n",
    "\n",
    "For the language models, create plots showing `NDCG@10` with varying values of the parameters. You can do this by chaining small scripts using shell scripting (preferred) or execute trec_eval using Python's `subprocess`.\n",
    "\n",
    "Compute significance of the results using a [two-tailed paired Student t-test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html) **[5 points]**. Be wary of false rejection of the null hypothesis caused by the [multiple comparisons problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). There are multiple ways to mitigate this problem and it is up to you to choose one.\n",
    "\n",
    "Analyse the results by identifying specific queries where different methods succeed or fail and discuss possible reasons that cause these differences. This is *very important* in order to understand who the different retrieval functions behave.\n",
    "\n",
    "**NOTE**: Donâ€™t forget to use log computations in your calculations to avoid underflows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: You should structure your code around the helper functions we provide below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "import shutil\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import scipy.spatial.distance as ssd\n",
    "import random\n",
    "import copy\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "import logging\n",
    "import pyndri\n",
    "import pyndri.compat\n",
    "import sys\n",
    "import scipy.spatial.distance as ssd\n",
    "import time\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering statistics about 456 terms.\n",
      "Inverted index creation took 30.186471462249756 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "    queries = parse_topics([f_topics])\n",
    "\n",
    "index = pyndri.Index('index/')\n",
    "\n",
    "num_documents = index.maximum_document() - index.document_base()\n",
    "\n",
    "dictionary = pyndri.extract_dictionary(index)\n",
    "\n",
    "tokenized_queries = {\n",
    "    query_id: [dictionary.translate_token(token)\n",
    "               for token in index.tokenize(query_string)\n",
    "               if dictionary.has_token(token)]\n",
    "    for query_id, query_string in queries.items()}\n",
    "\n",
    "query_term_ids = set(\n",
    "    query_term_id\n",
    "    for query_term_ids in tokenized_queries.values()\n",
    "    for query_term_id in query_term_ids)\n",
    "\n",
    "print('Gathering statistics about', len(query_term_ids), 'terms.')\n",
    "\n",
    "# inverted index creation.\n",
    "\n",
    "document_lengths = {}\n",
    "unique_terms_per_document = {}\n",
    "\n",
    "inverted_index = collections.defaultdict(dict)\n",
    "collection_frequencies = collections.defaultdict(int)\n",
    "\n",
    "total_terms = 0\n",
    "\n",
    "for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "    ext_doc_id, doc_token_ids = index.document(int_doc_id)\n",
    "\n",
    "    document_bow = collections.Counter(\n",
    "        token_id for token_id in doc_token_ids\n",
    "        if token_id > 0)\n",
    "    document_length = sum(document_bow.values())\n",
    "\n",
    "    document_lengths[int_doc_id] = document_length\n",
    "    total_terms += document_length\n",
    "\n",
    "    unique_terms_per_document[int_doc_id] = len(document_bow)\n",
    "\n",
    "    for query_term_id in query_term_ids:\n",
    "        assert query_term_id is not None\n",
    "\n",
    "        document_term_frequency = document_bow.get(query_term_id, 0)\n",
    "\n",
    "        if document_term_frequency == 0:\n",
    "            continue\n",
    "\n",
    "        collection_frequencies[query_term_id] += document_term_frequency\n",
    "        inverted_index[query_term_id][int_doc_id] = document_term_frequency\n",
    "\n",
    "\n",
    "avg_doc_length = total_terms / num_documents\n",
    "print('Inverted index creation took', time.time() - start_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  120  and  30  query ids for the test and valid sets.\n"
     ]
    }
   ],
   "source": [
    "test_query_ids = []\n",
    "with open('./ap_88_89/qrel_test', 'r') as test_queries:\n",
    "    for line in test_queries:\n",
    "        query_id = line.split(' ')[0]\n",
    "        if query_id not in test_query_ids:\n",
    "            test_query_ids.append(query_id)\n",
    "\n",
    "valid_query_ids = []\n",
    "with open('./ap_88_89/qrel_validation', 'r') as valid_queries:\n",
    "    for line in valid_queries:\n",
    "        query_id = line.split(' ')[0]\n",
    "        if query_id not in valid_query_ids:\n",
    "            valid_query_ids.append(query_id)\n",
    "            \n",
    "for i in range(0,len(valid_query_ids)):\n",
    "    valid_query_ids[i] = int(valid_query_ids[i])\n",
    "    \n",
    "valid_query_ids = sorted(valid_query_ids)\n",
    "\n",
    "for i in range(0,len(valid_query_ids)):\n",
    "    valid_query_ids[i] = str(valid_query_ids[i])\n",
    "            \n",
    "print('We have ',len(test_query_ids),' and ',len(valid_query_ids),' query ids for the test and valid sets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_retrieval(model_name,score_fn,plm_kernel=\"Triangle\",mu=0):\n",
    "    \"\"\"\n",
    "    Runs a retrieval method for all the queries and writes the TREC-friendly results in a file.\n",
    "    \n",
    "    :param model_name: the name of the model (a string)\n",
    "    :param score_fn: the scoring function (a function - see below for an example) \n",
    "    \"\"\"\n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "\n",
    "    if os.path.exists(run_out_path):\n",
    "        print(\"File already exists\")\n",
    "        return\n",
    "    \n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    print('Retrieving using', model_name)\n",
    "    data = {}\n",
    "    count = 0\n",
    "    if model_name == 'tfidf_valid' or model_name == 'BM25_valid':\n",
    "        for query_id, query in queries.items():\n",
    "            if query_id in valid_query_ids:\n",
    "                score = 0.0\n",
    "                query_word_ids = [token2id.get(query_token,0) for query_token in index.tokenize(query)] #get ids for all the words\n",
    "                query_word_ids = [word_id for word_id in query_word_ids if word_id > 0] #remove stop words\n",
    "                print(query_id)\n",
    "                for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "                    score = 0\n",
    "                    external_document_id,_ = index.document(int_doc_id) #Get the external doc id for this document\n",
    "                    for query_word in query_word_ids:\n",
    "                        if int_doc_id in inverted_index[query_word].keys():\n",
    "                            score += score_fn(int_doc_id,query_word,collection_frequencies[query_word])\n",
    "                        else: \n",
    "                            score += 0.0\n",
    "                        assert(isinstance(score,float))\n",
    "                    if query_id in data.keys():       \n",
    "                        data[query_id].append((tuple([score,str(external_document_id)])))\n",
    "                    else:\n",
    "                        data[query_id] = [((tuple([score,str(external_document_id)])))]\n",
    "    elif model_name == 'plm': #For the positional language models we have additional paramters we give to score_fn()\n",
    "        for query_id, query in queries.items():\n",
    "            if query_id in valid_query_ids:\n",
    "                start = time.time()\n",
    "                print(query_id,query)\n",
    "                query_ids = [token2id.get(query_token,0) for query_token in index.tokenize(query)] #get ids for all the words\n",
    "                query_ids = [word_id for word_id in query_ids if word_id > 0] #remove stop words\n",
    "                for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "                    external_document_id,_ = index.document(int_doc_id) #Get the external doc id for this document\n",
    "                    score = score_fn(int_doc_id, query_ids, plm_kernel,collection_frequencies,mu)\n",
    "                    if query_id in data.keys():\n",
    "                        data[query_id].append((tuple([score,str(external_document_id)])))\n",
    "                    else:\n",
    "                        data[query_id] = [((tuple([score,str(external_document_id)])))]\n",
    "                print(\"Elapsed time is: \", time.time()-start)\n",
    "    else: #model_name == 'JelinekMercer_valid' or model_name == 'Dirichlet_valid' or model_name == 'AbsoluteDiscounting_valid':\n",
    "        for query_id, query in queries.items():\n",
    "            if query_id in valid_query_ids:\n",
    "                query_ids = [token2id.get(query_token,0) for query_token in index.tokenize(query)] #get ids for all the words\n",
    "                query_ids = [word_id for word_id in query_ids if word_id > 0] #remove stop words  \n",
    "                print(query_id, query)\n",
    "                for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "                    external_document_id,_ = index.document(int_doc_id) #Get the external doc id for this document\n",
    "                    score = score_fn(int_doc_id, query_ids, collection_frequencies)\n",
    "                    if query_id in data.keys():       \n",
    "                        data[query_id].append((tuple([score,str(external_document_id)])))\n",
    "                    else:\n",
    "                        data[query_id] = [((tuple([score,str(external_document_id)])))]\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF and BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tfidf(int_document_id, query_term_id, document_term_freq):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term using teh TFIDF model\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_term_id: the query term id (assuming you have split the query to tokens)\n",
    "    :param document_term_freq: the document term frequency of the query term \n",
    "    \"\"\"\n",
    "    try:\n",
    "        score = float(np.log(1+inverted_index[query_term_id][int_document_id]) * np.log(num_documents/document_term_freq))\n",
    "    except:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def BM25(int_document_id, query_term_id, document_term_freq): \n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term using the BM25 model\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_term_id: the query term id (assuming you have split the query to tokens)\n",
    "    :param document_term_freq: the document term frequency of the query term \n",
    "    \"\"\"\n",
    "    k1 = 1.2\n",
    "    b = 0.75\n",
    "    # We ignore the sum including k3 since our queries are typically very short and therefore this part is not needed\n",
    "    score = ((k1+1)*inverted_index[query_term_id][int_document_id])/(k1*((1-b)+b*(document_lengths[int_doc_id]/avg_doc_length) \\\n",
    "            + inverted_index[query_term_id][int_document_id]))*(num_documents/document_term_freq)\n",
    "    \n",
    "    return score\n",
    "\n",
    "#run_retrieval('tfidf_valid', tfidf)\n",
    "#run_retrieval('BM25_valid', BM25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langauge models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_length = sum(collection_frequencies.values()) #get all counts of terms\n",
    "\n",
    "def JelinekMercer(int_document_id, query_ids, collection_frequencies):\n",
    "    \"\"\"\n",
    "    This function calculates the probability of a query using a LM with Jelinek Mercer smoothing\n",
    "    \"\"\"\n",
    "    lamb = 0.9 #We have to test 0.1/0.5/0.9\n",
    "    query_prob = 1\n",
    "    doc_length = len([i for i in index.document(int_document_id)[1] if i >0]) #get document length of non stopwords\n",
    "    for word_id in query_ids:\n",
    "        try:\n",
    "            word_prob = (1-lamb)*(inverted_index[word_id][int_document_id]/doc_length)\n",
    "        except:\n",
    "            word_prob = 0\n",
    "        word_prob += lamb*(collection_frequencies[word_id]/col_length)\n",
    "        query_prob *= word_prob \n",
    "    return query_prob\n",
    "\n",
    "#run_retrieval('JelinekMercer_valid_0.9', JelinekMercer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for JelinekMercer (./trec_eval -m map -m P.5 -m ndcg_cut.10 -m recall.1000 qrel_validation JelinekMercer_valid_0.1.run)\n",
    "\n",
    "Results for $\\lambda = 0.1$ are: map 0.2262, P_5 0.3733, recall_1000 0.6287 and ndcg_cut_10 0.3834.\n",
    "\n",
    "Results for $\\lambda = 0.5$ are: map 0.2249, P_5 0.4067, recall_1000 0.6226 and ndcg_cut_10 0.4011.\n",
    "\n",
    "Results for $\\lambda = 0.9$ are: map 0.1980, P_5 0.3533, recall_1000 0.5825 and ndcg_cut_10 0.3405.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKjULERGJSs1CRESiUrMQEZGo/h/kffjL76SBLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c008f6780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jelinekmercer_ndcg = [0.3834, 0.4011, 0.3405]\n",
    "jelinekmercer_lamb = [0.1, 0.5, 0.9]\n",
    "plt.plot(jelinekmercer_lamb, jelinekmercer_ndcg)\n",
    "plt.xlabel('Lambda for the Jelinek Mercer model')\n",
    "plt.ylabel('NDCG@10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Dirichlet(int_document_id, query_ids, collection_frequencies):\n",
    "    \"\"\"\n",
    "    This function calculates the probability of a query using a LM with Dirichlet smoothing\n",
    "    \"\"\"\n",
    "    mu = 1500 #We have to test 500/1000/1500\n",
    "    query_prob = 1\n",
    "    doc_length = len([i for i in index.document(int_document_id)[1] if i >0]) #get document length of non stopwords \n",
    "    for word_id in query_ids:\n",
    "        try:\n",
    "            word_prob = (doc_length/(mu+doc_length))*(inverted_index[word_id][int_document_id]/doc_length)\n",
    "        except:\n",
    "            word_prob = 0\n",
    "        word_prob += (mu/(mu+doc_length))*(collection_frequencies[word_id]/col_length)\n",
    "        query_prob *= word_prob \n",
    "    return query_prob\n",
    "\n",
    "#run_retrieval('Dirichlet_valid_1500', Dirichlet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Dirichlet (./trec_eval -m map -m P.5 -m ndcg_cut.10 -m recall.1000 qrel_validation Dirichlet_valid_0.1.run)\n",
    "\n",
    "Results for $\\mu = 500$ are: map 0.2252, P_5 0.4000, recall_1000 0.5944 and ndcg_cut_10 0.4007.\n",
    "\n",
    "Results for $\\mu = 1000$ are: map 0.2244, P_5 0.3733, recall_1000 0.5925 and ndcg_cut_10 0.3793.\n",
    "\n",
    "Results for $\\mu = 1500$ are: map 0.2233, P_5 0.3600, recall_1000 0.5854 and ndcg_cut_10 0.3732.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8VfX9x/HXJ4sRNgkowzJEFEEQ\nAsRqFZzYWrGtC1BBGbXV7trq79f2Z7VTW+2yrUwXo7ulS60WtI4EAoIIMgKCBEfCXjKSfH5/nBN6\nCBk3JDc34/18PO4j537PuJ9vLuR9zzn3nK+5OyIiIicrKdEFiIhI46YgERGRWlGQiIhIrShIRESk\nVhQkIiJSKwoSERGpFQWJiIjUioJERERqRUEiIiK1kpLoAupDRkaG9+rVK9FliIg0KsuWLdvu7pnV\nLdcsgqRXr17k5eUlugwRkUbFzLbEspwObYmISK0oSEREpFYUJCIiUisKEhERqRUFiYiI1IqCRERE\nakVBIiIitaIgqcK83Ld5cX1RossQEWnQFCSVOFJcylM5W5j6RB4vbdie6HJERBosBUkl0lKSeGrK\nSHpnpDP58aW8kq8wERGpSFyDxMzGmNk6M8s3s7urWO5aM3Mzy4q03ROut87MrqjpNutCp/Q05k4Z\nSa/O6dz2+FJe3bgjni8nItIoxS1IzCwZeAS4EhgAjDOzARUs1xb4PJAbaRsA3AicDYwBfmlmybFu\nsy51btOCuVNH0rNja257bCm5mxQmIiJR8dwjGQHku/smdz8CLADGVrDc/cADwKFI21hggbsfdve3\ngPxwe7Fus05ltGnBvKnZdOvQklsfW8rSzTvj/ZIiIo1GPIOkO7A18rwgbDvGzM4Ferr732Jct9pt\nRrY9zczyzCyvqKj237zKbNuC+VOzOaV9SybNXkKewkREBIhvkFgFbX5splkS8DDwlRqsW+U2j2t0\nn+7uWe6elZlZ7e30Y9KlXUvmT82mS7uWTJqzlOVv76qT7YqINGbxDJICoGfkeQ/gncjztsBAYLGZ\nbQaygYXhCffK1q1um3HXNQyTjDZpTJy1hBVbd9fny4uINDjxDJKlQD8z621maQQnzxeWzXT3Pe6e\n4e693L0XkANc7e554XI3mlkLM+sN9AOWVLfN+nJK+5bMn5ZNx/Q0bp6Vy0qFiYg0Y3ELEncvBu4E\nngHeBH7r7qvN7D4zu7qadVcDvwXWAE8Dd7h7SWXbjFcfqnJq+1bMn5ZNh9ap3Dwrl1UFexJRhohI\nwpl7hacYmpSsrCyP11C7BbsOcuP0HPYdKmbulJEM7N4+Lq8jIlLfzGyZu2dVt5yubK+lHh1bM39q\nNm1apHDTrFzWvLM30SWJiNQrBUkd6NkpCJPWqclMmJnDm+8qTESk+VCQ1JHTOrdm/rRsWqYmM2Fm\nLuve25fokkRE6oWCpA59qHM686dmk5psjJ+Rw/r3FSYi0vQpSOpYr4wgTJKTgjDJL1SYiEjTpiCJ\ngz6ZbZg3NRsz48bpueQX7k90SSIicaMgiZPTu7Rh/tSRAIyfkcOmIoWJiDRNCpI4Or1LW+ZPHUlJ\nqTNuRg5vbT+Q6JJEROqcgiTO+nVty7yp2RwtccZNz2GzwkREmhgFST3of0pb5k4ZyeHiEsbNyOHt\nHQcTXZKISJ1RkNSTs05tx9wp2XxwNAiTrTsVJiLSNChI6tGAbu14avJI9h8u5sbpORTsUpiISOOn\nIKlnA7u356nJI9l36CjjZuSwbfcHiS5JRKRWFCQJMKhHe56cPJLdB48ybnoO7yhMRKQRU5AkyOCe\nHXhy8kh2HTjCuBk5vLfnUKJLEhE5KQqSBBrSswOPTx7Bjv1BmLy/V2EiIo2PgiTBhp7WkcdvG07h\n3kOMm5FDocJERBoZBUkDMOxDnXjsthG8tycMk30KExFpPBQkDcTwXp2YM2k47+w+xIQZuWzffzjR\nJYmIxERB0oCM7NOZ2ZOGs3XXQcbPyGGHwkREGgEFSQNzXt/OzJ44nC07DjJhZi47DxxJdEkiIlVS\nkDRAHz49g1kTh/PW9gOMn5HDLoWJiDRgCpIG6oJ+Gcy4JYtN2w8wYWYuuw8qTESkYVKQNGAXnpHJ\n9JuHkV+4n5tm5bLn4NFElyQicgIFSQM3qn8XHr15GOvf28/Ns3PZ84HCREQaFgVJIzD6zC786qah\nvPnuXm6ZlcveQwoTEWk4FCSNxCVndeWXE4ax5t29TJy9hH0KExFpIOIaJGY2xszWmVm+md1dwfzb\nzWyVma0ws5fMbEDYnmZmc8J5K81sVGSdxeE2V4SPLvHsQ0Ny2YCu/GL8UFYV7GHi7CXsP1yc6JJE\nROIXJGaWDDwCXAkMAMaVBUXEPHcf5O5DgAeAh8L2qQDuPgi4DPixmUVrneDuQ8JHYbz60BBdcfYp\n/GL8uaws2MMkhYmINADx3CMZAeS7+yZ3PwIsAMZGF3D3vZGn6YCH0wOA58NlCoHdQFYca21Uxgw8\nlZ+PO5fXtu7mtjlLOaAwEZEEimeQdAe2Rp4XhG3HMbM7zGwjwR7J58PmlcBYM0sxs97AMKBnZLU5\n4WGtb5qZVfTiZjbNzPLMLK+oqKgu+tOgfHTQqfzkhiHkbdnJbY8t5eARhYmIJEY8g6SiP/B+QoP7\nI+7eF/g68I2weTZB8OQBPwFeAcr+Uk4ID3l9JHzcXNGLu/t0d89y96zMzMxadaSh+vjgbjx8wxCW\nbt7J5Mfy+OBISaJLEpFmKJ5BUsDxexE9gHeqWH4BcA2Auxe7+5fCcyBjgQ7AhnDetvDnPmAewSG0\nZmvskO48dP0Qct/awZQnlnLoqMJEROpXPINkKdDPzHqbWRpwI7AwuoCZ9Ys8/RhhWJhZazNLD6cv\nA4rdfU14qCsjbE8FrgLeiGMfGoVrzu3Oj64bzCsbdzD1iTyFiYjUq5R4bdjdi83sTuAZIBmY7e6r\nzew+IM/dFwJ3mtmlwFFgFzAxXL0L8IyZlQLb+O/hqxZhe2q4zeeAGfHqQ2PyyaE9KCl1vvaH15n2\n5DKm3zyMlqnJiS5LRJoBcz/htEWTk5WV5Xl5eYkuo178dulWvvaH1xnVP5NHbx5GixSFiYicHDNb\n5u7VfmNWV7Y3MdcP78n3PzmIxeuK+MxTyzlcrMNcIhJfCpImaNyI0/juJwby77WF3DF3OUeKSxNd\nkog0YQqSJmrCyA9x/9izee7NQu6ct5yjJQoTEYkPBUkTdvN5vfj21Wfz7Jr3+dy81xQmIhIXCpIm\nbuKHe/Gtqwbw9Or3+MIChYmI1L24ff1XGo7bLuhNqTvf+fubmK3gpzcMISVZnyFEpG4oSJqJKR/p\nQ6k73/vHWpLMePj6wQoTEakTCpJmZNqFfSkphR8+vZYkg4euH0JyUoX3vBQRiZmCpJn5zKi+lLrz\n4DPrSDbjwesGK0xEpFYUJM3QHaNPp7TU+fG/1pOUZDzwqXNIUpiIyElSkDRTn7ukHyXu/OS5DSQZ\n/OCTChMROTkKkmbsi5eeQWmp87N/55Nkxvc+MUhhIiI1piBp5r502RmUOvxiUT5JScZ3xg5UmIhI\njShImjkz4yuXn0GJO79avJEkg/vHDqSSEYxFRE6gIBHMjK9d0Z/SUufRFzeRbMa9V5+tMBGRmChI\nBAjC5O4rz6TUnRn/eQsz4/8+PkBhIiLVUpDIMWbG/3z0LEpKYfbLb5GcZHzjY2cpTESkSgoSOY6Z\n8c2rzqLUnVkvBWFyz5VnKkxEpFIKEjlB2WGtUnemv7gJM7h7jMJERCqmIJEKmRnfvvpsSt159IXg\nBPxdV/RXmIjICRQkUikz476rB1JSCr9cvJHkJOPLl52hMBGR4yhIpEpJScZ3rxmIu/Pz8Ar4L112\nRqLLEpEGREEi1UpKCm6fUlLq/PT5DSSZ8YVL+yW6LBFpIBQkEpOkJOMHnzqHUoeHn1tPchLcebHC\nREQUJFIDyUnGA9eeg7vzo2eDW9B/dtTpiS5LRBJMQSI1kpwUDIZV4s4DT68jyYzbL+qb6LJEJIHi\nOmi3mY0xs3Vmlm9md1cw/3YzW2VmK8zsJTMbELanmdmccN5KMxsVWWdY2J5vZj8zfYWo3iUnGT++\nbjAfH9yNH/xzLTNe3JTokkQkgeIWJGaWDDwCXAkMAMaVBUXEPHcf5O5DgAeAh8L2qQDuPgi4DPix\nmZXV+itgGtAvfIyJVx+kcinJSTx8/WA+NuhUvvuPN5n5H4WJSHMVz0NbI4B8d98EYGYLgLHAmrIF\n3H1vZPl0wMPpAcDz4TKFZrYbyDKzrUA7d3813OYTwDXAP+PYD6lESnISP7lxCKXufOfvb5KcZNx6\nfu9ElyUi9azaPRIzSzGzT5vZ02b2enio6Z/hYanUKlbtDmyNPC8I28pv/w4z20iwR/L5sHklMDZ8\n7d7AMKBnuH5BdduU+pOanMTPxp3LFWd35dt/XcMTr25OdEkiUs9iObT1JDAEuBf4KPAx4NvAYOCp\nKtar6NyFn9Dg/oi79wW+DnwjbJ5NEBJ5wE+AV4DiWLcJYGbTzCzPzPKKioqqKFNqKzU5iZ+PG8pl\nA7ryrb+s5smcLYkuSUTqUSyHtoa6e/9ybQVAjpmtr2K9AoK9iDI9gHeqWH4BwfkP3L0Y+FLZDDN7\nBdgA7Aq3U+023X06MB0gKyurwrCRupOWksQj44fy2bnL+Oaf3yDZjPEjT0t0WSJSD2LZI9llZtdF\nTnZjZklmdgPBH/bKLAX6mVlvM0sDbgQWRhcws+gVbR8jCAvMrLWZpYfTlwHF7r7G3d8F9plZdvht\nrVuAv8TQB6kHaSlJPDJhKBef2YX/+dMqFix5O9EliUg9iGWP5Ebgh8AvzawsODoAi8J5FXL3YjO7\nE3gGSAZmu/tqM7sPyHP3hcCdZnYpcJQglCaGq3cBnjGzUmAbcHNk058BHgNaEZxk14n2BqRFSjK/\nnDCUTz+5jHv+tIokM64f3rP6FUWk0TL32I/6mFnncJ3t8Sup7mVlZXleXl6iy2hWDh0tYeoTebyU\nv50Hrx3MtcN6VL+SiDQoZrbM3bOqW65G15G4+45oiISHnURO0DI1mRm3ZHF+3wzu+v1K/ri8oPqV\nRKRRqu0FibPqpAppksrC5Lw+nfnq71bylxXbEl2SiMRBtedIzGxhZbOAznVbjjQ1rdKSmTVxOLc+\ntoQv/WYFZsbVg7sluiwRqUOxnGz/CHATsL9cuxFcvS5SpVZpycyeNJxJc5byxQWvkWRw1TkKE5Gm\nIpYgyQEOuvsL5WeY2bq6L0maotZpKcyZNJxJc5bwhQUrSDLjo4NOTXRZIlIHqj1H4u5XuvuiSuZd\nWPclSVOV3iKFObeO4NyeHfj8/Nd4+o33El2SiNSBGp9sN7PO0YsTRWqiTYsU5tw6nHN6tOfOect5\ndrXCRKSxiykQzKyjmf3CzF4guDX802Y2u+zqc5GaaNsylcduG8HA7u25Y95ynlvzfqJLEpFaiOXu\nvx2AfwB/cPeL3P1Gd7+c4GaOPzCzC8ysTbwLlaalXctUnpg8ggGntuMzc5fx77UKE5HGKpY9km8C\nP3L3RWb2pJltMLNXCW6I2D3cxv/Es0hpmoIwGcmZp7Tj9ieXs2hdYaJLEpGTEEuQXOTufwinDwPj\n3P084AZgB/AScFGc6pMmrn2rVJ6cPIJ+Xdvw6SeX8cJ63fJfpLGJJUhaRMZFP5dg0CmANwhuMV8K\ntI5HcdI8dGidxtwpIzk9sw1Tn8jjPxsUJiKNSSxBsgS4JJz+FfCsmX2P4K6+j5rZcGB1nOqTZqIs\nTPpkpDPl8Txezm9U9wUVadZiCZLvEpxU7+ruM4HrgD+HP/8O/By4P34lSnPRMT0Ik16d05n8+FJe\n2agwEWkMYrkgcRNwB7DQzO4HRgKdCMZX/ydwl7vrCnepE53btGDu1JH07Nia2x5bSs6mHYkuSUSq\nEdN1JO6eC5wHvAicBQwiGEd9qLv/J37lSXOU0aYF86Zm06Nja26ds5Qlb+1MdEkiUoWYr1B391J3\n/5e7/8jdH3T3p8Ox1UXqXGbbFsybOpJuHVoyac4S8jYrTEQaqlguSJxsZndFnheY2V4z22dmn4lv\nedKcdWnbkvlTszmlXUsmzl7Csi0KE5GGKJY9ktuB2ZHnRe7eDsgExsWlKpFQl3YtmTc1m8y2LZg4\neynL396V6JJEpJxYgiTJ3aNnPH8H4O6HgFZxqUok4pT2LZk/LZvObdKYOGsJK7buTnRJIhIRS5C0\njz5x9+8BhHcA1giJUi9Obd+K+VOz6Ziexs2zcnm9QGEi0lDEEiTPmtl3Kmi/D3i2jusRqVS3Dq2Y\nPy2b9q1SuWlmLm9s25PokkSE2ILkLqCvmeWb2R/CRz5wOvDV+JYncrzuHYI9k7YtU5mgMBFpEGK5\nIPGAu48DLgceCx9XhLeTLz+Ou0jc9ezUmgXTsklPS+amWbmseWdvoksSadZi+frvFWZ2rbtvcve/\nho+NZjbBzC6rjyJFygvC5DxapSYzYWYOa99TmIgkSiyHtr4NvFBB+/ME50lEEuK0zq2ZPzWbFinJ\njJ+Ry7r39iW6JJFmKZYgae3uJ9zX293fAzTUriRUr4x05k/LJiXJGD8jhw3vK0xE6lssQdLSzFLK\nN5pZKtVcR2JmY8xsXXii/u4K5t9uZqvMbIWZvWRmA8q2bWaPh/PeNLN7IutsjqyTF0P90sT1DsMk\nKckYNyOX/EKduhOpT7EEyR+BGWZ2bO8jnP51OK9CZpYMPAJcCQwAxpUFRcQ8dx/k7kOAB4CHwvbr\ngBbuPggYBnzazHpF1hvt7kPcPSuG+qUZ6JvZhvlTswEYNyOHjUUKE5H6EkuQfAN4H9hiZsvMbDmw\nGSgK51VmBJAfnqQ/AiwAxkYXcPfoGdJ0wMtmAenhnlAr4Aigs6lSpdO7tGH+1JG4O+Om57BJYSJS\nL2L5+m+xu98N9AQmAROB09z9bnc/WsWq3YGtkecFYdtxzOwOM9tIsEfy+bD598AB4F3gbeBH7l52\nxz4nuEhymZlNq65+aV76dW3L3CnZFJc642bksHn7gUSXJNLkxXQbeTPrDEwhuIHj7cDksK3K1Spo\n8xMa3B9x977A1/nvHs4IoAToBvQGvmJmfcJ557v7UIJDZneY2YWV1DzNzPLMLK+oSGOANyf9T2nL\nvKkjOVJcyrgZOWzZoTARiadYriM5C3iD4FzFemADMBxYZWZnVrFqAcFeTJkewDtVLL8AuCacHg88\n7e5H3b0QeBnIAnD3d8KfhcCfCELnBO4+3d2z3D0rMzOz6k5Kk3PmKe2YOyWbD46WMG56Dm/vOJjo\nkkSarFj2SO4HvuDuk9z9p+7+E3efCHyOYDz3yiwF+plZbzNLA24EFkYXMLN+kacfIwgpCA5nXWyB\ndCAbWGtm6WbWNlw3neBq+zdi6IM0QwO6tWPulJEcOFLCuBk5bN2pMBGJh1iCZJC7/7Z8o7v/ARhY\n2Urh6Il3As8AbwK/dffVZnafmV0dLnanma02sxXAlwnOv0Dwba82BCGxFJjj7q8DXYGXzGwlsAT4\nu7s/HUtHpXk6u1t75k4Zyb5DRxk3I4eCXQoTkbpm7iectjh+AbPl4TmJGs1rSLKysjwvT5ecNGer\nCvYwfmYOHVqn8ptp59Gtg4bSEamOmS2L5TKLEy40rEAXM/tyRa9BMEqiSIM3qEd7npo8kptm5jJu\nRg4LpmVzanuFiUhdiOXQ1gygbQWPNsDM+JUmUrcG9+zAE5NHsGP/EcZNz+G9PYcSXZJIk1Dtoa2m\nQIe2JGrZll3cMiuXru1asmBaNl3atUx0SSINUqyHtmI5R/KtKma7u99f0+Lqm4JEysvbvJNbZi/h\nlPZhmLRVmIiUF2uQxHJo60AFD4DJBBcRijQ6Wb068ditI3hvzyHGz8ilaN/hRJck0mjFcouUH5c9\ngOkE9766leACwj5VrizSgI3o3YnZk4azbdcHjJ+Rw/b9ChORkxHrLVI6mdl3gNcJvuk11N2/Hl5d\nLtJoZffpzKxJWWzddZAJM3LZoTARqbFYbpHyIMFFgfsILk681913xb0ykXry4b4ZzJo4nM07DjBh\nZi47DxxJdEkijUoseyRfIbh54jeAd8xsb/jYZ2a6tbs0CeefnsHMiVls2n6Am2bmskthIhKzWM6R\nJLl7K3dv6+7tIo+27t6uPooUqQ8f6ZfJjFuyyC/az02zctl9UGEiEouYzpGINBcXnZHJozcPY8P7\n+7l51hL2HKxqyB0RAQWJyAlG9+/Cr28eytr39nLL7Fz2fKAwEamKgkSkAhef2ZVfTRjGmnf3csvs\nJew9pDARqYyCRKQSlw7oyiPjh7J62x4mzl7CPoWJSIUUJCJVuPzsU/jF+KGsKtjDpDlL2X+4ONEl\niTQ4ChKRaowZeAo/H3cuK7bu5tY5SzigMBE5joJEJAZXDjqVn944hOVv7+bWx5Zy8IjCRKSMgkQk\nRled042HbxhC3uad3PbYUj44UpLokkQaBAWJSA1cPTgIkyVv7WTy4woTEVCQiNTY2CHd+fH1g3l1\n0w6mPpHHoaMKE2neFCQiJ+ET5/bgwWsH8/LG7QoTafYUJCIn6dphPfjhp87hpfztfPrJZQoTabYU\nJCK1cH1WT37wyUG8sL6Izzy1jMPFChNpfhQkIrV0w/DT+N4nBrFoXRGffWq5wkSaHQWJSB0YP/I0\n7r9mIM+vLeSOua9xpLg00SWJ1BsFiUgduTn7Q9w39myee/N9Pjd/OUdLFCbSPChIROrQLef14t6P\nD+CZ1e/z+fmvKUykWYhrkJjZGDNbZ2b5ZnZ3BfNvN7NVZrbCzF4yswFhe6qZPR7Oe9PM7ol1myKJ\nNun83nzzqgH88433+OKCFRQrTKSJS4nXhs0sGXgEuAwoAJaa2UJ3XxNZbJ67/zpc/mrgIWAMcB3Q\nwt0HmVlrYI2ZzQe2xrBNkYSbfEFvSkud7/7jTczgJzcMISVZBwCkaYpbkAAjgHx33wRgZguAscCx\nP/ruvjeyfDrgZbOAdDNLAVoBR4C9sWxTpKGYemEfSt35/j/XkpxkPHT9EJKTLNFlidS5eAZJd4I9\niDIFwMjyC5nZHcCXgTTg4rD59wQB8S7QGviSu+80s5i2KdJQfPqivpS488DT60gy40fXDVaYSJMT\nzyCp6H+Ln9Dg/gjwiJmNB74BTCTY8ygBugEdgf+Y2XOxbhPAzKYB0wBOO+20k6lfpE58dtTplJY6\nP3p2PWbw4LUKE2la4hkkBUDPyPMewDtVLL8A+FU4PR542t2PAoVm9jKQRbA3EtM23X06MB0gKyur\nwrARqS93XtyPklJ4+Ln1JJnxwKfOIUlhIk1EPM/+LQX6mVlvM0sDbgQWRhcws36Rpx8DNoTTbwMX\nWyAdyAbWxrJNkYbqC5f24wuX9OP3ywq454+rKC3V5xtpGuK2R+LuxWZ2J/AMkAzMdvfVZnYfkOfu\nC4E7zexS4Ciwi+CwFgTfzJoDvEFwOGuOu78OUNE249UHkbr2xUv7UerOz/+dT1ISfPeaQdozkUbP\n3Jv+p6KsrCzPy8tLdBkiALg7Dz6zjl8u3sjlA7ryqWE9OP/0DNq0iOeRZpGaM7Nl7p5V3XL6lytS\nz8yMu67oT4uUZGb8ZxPPrnmf1GRjRO9OjO7fhVH9u9A3Mx0z7alI46A9EpEEOlJcyrItu1i8rpBF\n6wpZ//5+AHp0bMXo/l0YfWYm5/XJoFVacoIrleYo1j0SBYlIA1Kw6yCL1xWxeF0RL+dv54OjJaSl\nJJHdpzOj+2cyun8XemWkJ7pMaSYUJBEKEmmMDheXsOStnSxaW8Ti9YVsKjoAQO+MdC46I5PRZ3Zh\nZO9OtEzV3orEh4IkQkEiTcGWHQdYvK6IResKeXXjDg4Xl9IyNYnz+2Ywqn8mo/p3oWen1okuU5oQ\nBUmEgkSamkNHS3h10w4Wry1k0boi3t55EIDTu7RhdBgqw3t1Ii1FN4qUk6cgiVCQSFPm7mzafiA8\nt1JI7qadHCkpJT0tmfNPz2D0mV0Y1T+TU9u3SnSp0sjo678izYSZ0TezDX0z2zD5gt4cOFzMqxt3\nsGhdIYvXFfHsmvcBOPOUtozq34XR/TMZ+qGOpOq29lJHtEci0oS5OxsK97NobRAqSzfvpLjUadsy\nhY/0y2BU/y6MOiOTLu1aJrpUaYB0aCtCQSIS2HfoKC/nbz920v79vYcBGNi9HaPOCK5bGdKzo+5O\nLICC5DgKEpETuTtvvruPResKeWFdEcve3kVJqdOhdSoX9stkVP9MLjojk85tWiS6VEkQBUmEgkSk\nensOHuU/+UUsWlvEC+uL2L7/MGZwTo8Ox74Jdk739rrJZDOiIIlQkIjUTGmps/qdvSwKb92yYutu\n3KFzehoXnZHJqDO7cGG/DDq0Tkt0qRJHCpIIBYlI7ew8cIT/bChi0dpCXlhfxK6DR0kyOPe0jsf2\nVs7u1k43mmxiFCQRChKRulNS6qws2H3supXXC/YAkNm2BaPCW7dc0C+Ddi1TE1yp1JaCJEJBIhI/\nRfsO88L6IFReXF/E3kPFpCQZwz7UMbhu5cxM+ndtq72VRkhBEqEgEakfxSWlvLZ197HrVta8uxeA\nU9u3DK5Z6Z+pQbwaEQVJhIJEJDHe23OIF9YXsmhtES/lb2f/4eJyg3hl0jezjfZWGigFSYSCRCTx\nNIhX46MgiVCQiDQ823Z/EITKWg3i1VApSCIUJCINW9kgXmW3bikbxKtX59bhCXsN4pUICpIIBYlI\n41I2iNfidYW8EhnE68N9M45dt6JBvOJPQRKhIBFpvKoaxKvsuhUN4hUfCpIIBYlI0+DuvLX9AIs0\niFe90MBWItLkmBl9MtvQJ8ZBvEb1z2SYBvGKO+2RiEiTUDaIV9k3wY4N4tUihY+coUG8ToYObUUo\nSESan2AQrx3HrlspG8Tr7G7tjl23okG8qtYggsTMxgA/BZKBme7+g3LzbwfuAEqA/cA0d19jZhOA\nuyKLngMMdfcVZrYYOBX4IJx3ubsXVlWHgkSkeatqEK+P9MtktAbxqlDCg8TMkoH1wGVAAbAUGOfu\nayLLtHP3veH01cBn3X1Mue0MAv7i7n3C54uBr7p7zMmgIBGRqKoG8Sr7JpgG8WoYJ9tHAPnuviks\naAEwFjgWJGUhEkoHKkq1ccD7sK3KAAAMwklEQVT8ONYpIs1M+9apXHVON646p9sJg3j97N8b+Onz\nG44N4nVRuLeiQbwqF88g6Q5sjTwvAEaWX8jM7gC+DKQBF1ewnRsIAihqjpmVAH8AvuPN4USPiMRF\nUpIxqEd7BvVoz+cv6XfcIF6L1hXyx9e2nTCI14BT2zX7vZWoeB7aug64wt2nhM9vBka4++cqWX58\nuPzESNtIgnMrgyJt3d19m5m1JQiSp9z9iQq2Nw2YBnDaaacN27JlSx32TkSag+Y+iFdDOEdyHnCv\nu18RPr8HwN2/X8nyScAud28faXsYKHL371WyziQgy93vrKoWnSMRkbpQtO8wL64P7gdWNohXcjiI\n1+gmOIhXQwiSFIKT7ZcA2whOto9399WRZfq5+4Zw+uPA/5UVHQbL28CFkfMsKUAHd99uZqkE506e\nc/dfV1WLgkRE6lrVg3gFh8Aa+yBeCT/Z7u7FZnYn8AzB139nu/tqM7sPyHP3hcCdZnYpcBTYBUyM\nbOJCoKAsREItgGfCEEkGngNmxKsPIiKVSUlOYnivTgzv1YmvjTnzuEG8/rryXeYv2XpsEK9RZwR7\nK011EC9dkCgiUseqG8RrVP9MzuvbmdZpDXtvJeGHthoSBYmIJFJ1g3iN6t+F3g1wEC8FSYSCREQa\nisPFJSx9a9ex61Ya8iBeCpIIBYmINFRv7zjI4vWFLFrb8AbxUpBEKEhEpDGobBCvvpnp4deL63cQ\nLwVJhIJERBqb6gbxKhtvpVuH+A3ilfCv/4qIyMlrTIN4aY9ERKSRcXfyC/cHJ+zjOIiXDm1FKEhE\npCmrahCvJ24bcdLjrOjQlohIM9G2ZSpjBp7CmIGnHBvEa/H6QlZu3U2n9Pjf/l5BIiLShJgZA7q1\nY0C3dvX2mvV/VkZERJoUBYmIiNSKgkRERGpFQSIiIrWiIBERkVpRkIiISK0oSEREpFYUJCIiUivN\n4hYpZlYEbEl0HTWUAWxPdBH1TH1uHtTnxuND7p5Z3ULNIkgaIzPLi+UeN02J+tw8qM9Njw5tiYhI\nrShIRESkVhQkDdf0RBeQAOpz86A+NzE6RyIiIrWiPRIREakVBUkCmVkHM/u9ma01szfN7Dwz62Rm\n/zKzDeHPjuGyZmY/M7N8M3vdzIYmuv6aMrMvmdlqM3vDzOabWUsz621muWF/f2NmaeGyLcLn+eH8\nXomtPnZmNtvMCs3sjUhbjd9XM5sYLr/BzCYmoi+xqKS/D4b/rl83sz+ZWYfIvHvC/q4zsysi7WPC\ntnwzu7u++1ETFfU5Mu+rZuZmlhE+b/TvcbXcXY8EPYDHgSnhdBrQAXgAuDtsuxv4YTj9UeCfgAHZ\nQG6i669hX7sDbwGtwue/BSaFP28M234NfCac/izw63D6RuA3ie5DDfp6ITAUeCPSVqP3FegEbAp/\ndgynOya6bzXo7+VASjj9w0h/BwArgRZAb2AjkBw+NgJ9wv8LK4EBie5bTfoctvcEniG4bi2jqbzH\n1T20R5IgZtaO4B/jLAB3P+Luu4GxBAFD+POacHos8IQHcoAOZnZqPZddWylAKzNLAVoD7wIXA78P\n55fvb9nv4ffAJWZm9VjrSXP3F4Gd5Zpr+r5eAfzL3Xe6+y7gX8CY+FdfcxX1192fdffi8GkO0COc\nHgsscPfD7v4WkA+MCB/57r7J3Y8AC8JlG6RK3mOAh4GvAdGTz43+Pa6OgiRx+gBFwBwze83MZppZ\nOtDV3d8FCH92CZfvDmyNrF8QtjUK7r4N+BHwNkGA7AGWAbsjf3CifTrW33D+HqBzfdZcx2r6vjbq\n97uc2wg+kUMT7q+ZXQ1sc/eV5WY12T6XUZAkTgrBrvGv3P1c4ADBIY/KVPRpvNF85S48JzCW4HBG\nNyAduLKCRcv61Kj7WwOV9bNJ9N/M/hcoBuaWNVWwWKPvr5m1Bv4X+FZFsytoa/R9jlKQJE4BUODu\nueHz3xMEy/tlh6zCn4WR5XtG1u8BvFNPtdaFS4G33L3I3Y8CfwQ+TLCbnxIuE+3Tsf6G89tT8aGE\nxqKm72tjf78JTx5fBUzw8KQATbe/fQk+JK00s80E9S83s1Noun0+RkGSIO7+HrDVzPqHTZcAa4CF\nQNm3NyYCfwmnFwK3hN8AyQb2lB0qaSTeBrLNrHV4rqOsv4uAa8Nlyve37PdwLfDvyB+jxqim7+sz\nwOVm1jHcm7s8bGsUzGwM8HXganc/GJm1ELgx/FZeb6AfsARYCvQLv8WXRvAFi4X1XffJcvdV7t7F\n3Xu5ey+CkBga/j9vku/xcRJ9tr85P4AhQB7wOvBngm9udAaeBzaEPzuFyxrwCME3W1YBWYmu/yT6\n+21gLfAG8CTBN3f6EPwhyQd+B7QIl20ZPs8P5/dJdP016Od8gvNARwn+oEw+mfeV4NxCfvi4NdH9\nqmF/8wmO/68IH7+OLP+/YX/XAVdG2j8KrA/n/W+i+1XTPpebv5n/fmur0b/H1T10ZbuIiNSKDm2J\niEitKEhERKRWFCQiIlIrChIREakVBYmIiNSKgkTqjJntj8M2N5fdRbUuX9vMrrPgjsuLTrKuDmb2\n2cjzUWb2t5PZVrj+vWa2zcxWhHeC/aOZDYjMnxl9Xm7dSudFtv3VSuZV+Xsr3894iuW9jvXfg9Qv\nBYk0V5OBz7r76FgWjlx9X6YDwR2K69LD7j7E3fsBvwH+bWaZAO4+xd3XVFBXcmXz6kg8+ilNjIJE\n4srMPm7BeCKvmdlzZtY1bL/XzB43s2fDT5mfNLMHzGyVmT1tZqmRzdxlZkvCx+nh+r3N7FUzW2pm\n90der42ZPW9my8NtnXAHWTP7FnAB8GsLxs1oaWZzwuVfM7PR4XKTzOx3ZvZX4Nlym/kB0Dfcg3gw\nbGtj/x1fZm7Z3YrNbJiZvWBmy8zsGYvhrs3u/pvwNceH21hsZlnh9H4zu8/McoHzys0bE/Z9pZk9\nH9nkgHC5TWb2+Ureq7vC3+frZvbtKvpZtnyvsK8zLRhjZq6ZXWpmL4d7VSPC5TqZ2Z/D7eaY2Tlh\ne+fw/X/NzB4lcu8pM7spfL9XmNmjZpZc3e9MEijRV0Tq0XQewP4K2jry3yGdpwA/DqfvBV4CUoHB\nwEHCq5yBPwHXhNObCa9yBm4B/hZOLwRuCafvKHttgpthtgunMwiuGLYK6lpMeIUx8BVgTjh9JsHt\nXFoSjJdSQHgVern1e3H8+BujCO5Q3IPgA9qrBGGVCrwCZIbL3QDMrmB79wJfLdf2RYKbepav14Hr\ny/cFyCS4mrx32N4psu1XCO4kkAHsAFKj7xnB7TmmE/wxTwL+RjDMwXH9rOB3UAwMCtdZBswOtzEW\n+HO43M+B/wunLwZWhNM/A74VTn8s7FcGcBbw10iNv4y815sJrxjXo+E8yu+ui9S1HsBvwk/haQSD\nW5X5p7sfNbNVBAMbPR22ryL4I1VmfuTnw+H0+cCnwuknCQZPguCP2PfM7EKglOC23F2B96qo8QKC\nP3a4+1oz2wKcEc77l7vHerPIJe5eAGBmK8I+7AYGAv8Kd1CSCW6tEYvKxl8pAf5QQXs28KIH43xQ\nru6/u/th4LCZFRL8Tgoi8y8PH6+Fz9sQ3Afr7WpqfMvdVwGY2WrgeXf38D3tFS5zAeF75e7/DvdE\n2hME1SfD9r+b2a5w+UuAYcDS8HfWiv/e5FIaIAWJxNvPgYfcfaGZjSL4dFzmMIC7l5rZUQ8/chIE\nQPTfpscwXWYCwSfzYWFIbSbYu6hKVQNmHahm3ajDkekSgj4YsNrdz6vBdsqcS3AvtvIOuXtJBe1G\n5bchr6i28ut+390fPa6x+iGOo9stjTyPvodV3S69onoNeNzd76nmtaWB0DkSibf2wLZw+mTHpL4h\n8vPVcPplgjvEQhAe0dcrDENkNPChGLb/Ytk2zOwM4DSCGwpWZR/QNoZtrwMyzey8cPupZnZ2dSuZ\n2acI9hDmV7dsxKvARRbcVRcz61SDdZ8BbjOzNuG63c2sC7H3syrR3+8oYLu77y3XfiXBYVAIbmp5\nbfj6ZedYYnkfJUG0RyJ1qbWZRQ+XPESwB/I7M9tGMORq75PYbovwxHISMC5s+wIwz8y+wPGHeeYC\nfzWzPIK7zq6NYfu/JDjxvorgmP8kdz9sVYzs6+47wpPKbxCM/vf3SpY7YmbXAj8LD+ekAD8BVlew\n+JfM7CaCQb/eAC5296IY6i97rSIzmwb80cySCA4HXRbjus+a2VnAq2G/9wM3ufvGaD/d/a5Y64m4\nl2Ak0NcJzoWVfaD4NjDfzJYDLxAeRnP3NWb2DeDZsB9HCc6DbTmJ15Z6oLv/iohIrejQloiI1IqC\nREREakVBIiIitaIgERGRWlGQiIhIrShIRESkVhQkIiJSKwoSERGplf8HdlNnkBw8c28AAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3bfe72fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirichlet_ndcg = [0.4007, 0.3793, 0.3732]\n",
    "dirichlet_lamb = [500, 1000, 1500]\n",
    "plt.plot(dirichlet_lamb, dirichlet_ndcg)\n",
    "plt.xlabel('Lambda for the Dirichlet model')\n",
    "plt.ylabel('NDCG@10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AbsoluteDiscounting(int_document_id, query_ids, collection_frequencies):\n",
    "    \"\"\"\n",
    "    This function calculates the probability of a query using a LM with Absolute discounting\n",
    "    \"\"\"\n",
    "    delta = 0.9 #We have to test 0.1/0.5/0.9\n",
    "    query_prob = 1\n",
    "    doc_length = len([i for i in index.document(int_document_id)[1] if i >0]) #get document length of non stopwords\n",
    "    doc_unique_length = len(np.unique([i for i in index.document(int_document_id)[1] if i >0]))\n",
    "    if doc_length != 0:\n",
    "        sigma = delta*(doc_unique_length/doc_length) \n",
    "    else:\n",
    "        sigma = delta\n",
    "    for word_id in query_ids:\n",
    "        try:\n",
    "            word_prob = max(inverted_index[word_id][int_document_id]-delta,0)/doc_length\n",
    "        except:\n",
    "            word_prob = 0\n",
    "        word_prob += sigma*(collection_frequencies[word_id]/col_length)\n",
    "        query_prob *= word_prob \n",
    "    return query_prob\n",
    "\n",
    "#run_retrieval('AbsoluteDiscounting_valid_0.9', AbsoluteDiscounting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Absolute discounting (./trec_eval -m map -m P.5 -m ndcg_cut.10 -m recall.1000 qrel_validation AbsoluteDiscounting_valid_0.1.run)\n",
    "\n",
    "Results for $\\delta = 0.1$ are: map 0.2180, P_5\t0.3933, recall_1000 0.6145 and ndcg_cut_10 0.3791.\n",
    " \n",
    "Results for $\\delta = 0.5$ are: map 0.2296, P_5 0.4067, recall_1000 0.6424 and ndcg_cut_10 0.3989.\n",
    "\n",
    "Results for $\\delta = 0.9$ are: map 0.2248, P_5 0.3600, recall_1000 0.6231 and ndcg_cut_10 0.3802.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/42CUTAKaAJGK5hRMApGwSgYBTQBAB1YP1dNSmaUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3bfc680278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "absdiscounting_ndcg = [0.3791, 0.3989, 0.3802]\n",
    "absdiscounting_lamb = [0.1, 0.5, 0.9]\n",
    "plt.plot(absdiscounting_lamb, absdiscounting_ndcg)\n",
    "plt.xlabel('Lambda for the Absolute Discounting model')\n",
    "plt.ylabel('NDCG@10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Kernel functions\n",
    "def gaussian_kernel(i,j,sigma):\n",
    "    return np.exp(-(i-j)**2 / (2*sigma**2))\n",
    "\n",
    "def circle_kernel(i,j,sigma):\n",
    "    delta = abs(i-j)\n",
    "    if delta > sigma:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sqrt(1-(delta/sigma)**2)\n",
    "\n",
    "def triangle_kernel(i,j,sigma):\n",
    "    delta = abs(i-j)\n",
    "    if delta > sigma:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (abs(j-1)/sigma)\n",
    "\n",
    "def hamming_kernel(i,j,sigma):\n",
    "    delta = abs(i-j)\n",
    "    return 0.5*(1 + np.cos(delta*np.pi/sigma))\n",
    "\n",
    "def passage_kernel(i,j,sigma):\n",
    "    delta = abs(i-j)\n",
    "    if delta > sigma:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def calc_denominator(int_doc_id,sigma,kernel_function):\n",
    "    _, doc_token_ids = index.document(int_document_id)\n",
    "    denominator = [0]*len(doc_token_ids)\n",
    "    for i in range(0,len(doc_token_ids)):\n",
    "         for j in range(0,len(doc_token_ids)):\n",
    "                denominator[i] += kernel_function(i,j,sigma)\n",
    "    return denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plm(int_document_id,query,kernel,collection_frequencies,mu):\n",
    "    \"\"\"\n",
    "    This functon returns the maximum value in the document using a positinal language model with 5 different kernels.\n",
    "    We also use dirichlet smoothing with the paramter mu.\n",
    "    \"\"\"\n",
    "    sigma = 50\n",
    "    denom = 0\n",
    "    score = 0\n",
    "    scores = []\n",
    "\n",
    "    unique_query_term_ids = set(query)\n",
    "    _, doc_token_ids = index.document(int_document_id)\n",
    "\n",
    "    if unique_query_term_ids.intersection(doc_token_ids) == 0:\n",
    "    #check if at least one query term is in the document\n",
    "        return 0\n",
    "    else:\n",
    "        if len(doc_token_ids) == 0:\n",
    "            return 0\n",
    "        scores = np.zeros(len(doc_token_ids))\n",
    "\n",
    "        if kernel == \"Gaussian\":\n",
    "            denom = calc_denominator(int_document_id,sigma,gaussian_kernel)\n",
    "        if kernel == \"Triangle\":\n",
    "            denom = calc_denominator(int_document_id,sigma,triangle_kernel)\n",
    "        if kernel == \"Hamming\":\n",
    "            denom = calc_denominator(int_document_id,sigma,hamming_kernel)\n",
    "        if kernel == \"Circle\":\n",
    "            denom = calc_denominator(int_document_id,sigma,circle_kernel)\n",
    "        if kernel == \"Passage\":\n",
    "            denom = calc_denominator(int_document_id,sigma,passage_kernel)\n",
    "\n",
    "        if kernel == \"Gaussian\":\n",
    "            for i in range(0,len(doc_token_ids)):\n",
    "                if doc_token_ids[i] in unique_query_term_ids:\n",
    "                    for j in range(0,len(doc_token_ids)):\n",
    "                        score = gaussian_kernel(i,j,sigma)+mu*(collection_frequencies[doc_token_ids[i]]/total_terms)\n",
    "                        #denom = 1*np.exp(-(i-j)**2/(2*sigma**2))+mu\n",
    "                        scores[j] += score/(denom[i]+mu)\n",
    "                        score = 0\n",
    "        else:\n",
    "            for i in range(0,len(doc_token_ids)):\n",
    "                if doc_token_ids[i] in unique_query_term_ids:\n",
    "                    for j in range(max(0,i-50),min(i+sigma,len(doc_token_ids))):\n",
    "                    #in order to make it faster we only check the relevant indices given by sigma\n",
    "                        if kernel == 'Triangle':\n",
    "                            score = triangle_kernel(i,j,sigma)+mu*(collection_frequencies[doc_token_ids[i]]/total_terms)\n",
    "                            #denom = 1*np.exp(-(i-j)**2/(2*sigma**2))+mu\n",
    "                            scores[j] += score/(denom[i]+mu)\n",
    "                            score = 0\n",
    "                        if kernel == 'Hamming':\n",
    "                            score = hamming_kernel(i,j,sigma)+mu*(collection_frequencies[doc_token_ids[i]]/total_terms)\n",
    "                            #denom = 1*np.exp(-(i-j)**2/(2*sigma**2))+mu\n",
    "                            scores[j] += score/(denom[i]+mu)\n",
    "                            score = 0\n",
    "                        if kernel == 'Circle':\n",
    "                            score = circle_kernel(i,j,sigma)+mu*(collection_frequencies[doc_token_ids[i]]/total_terms)\n",
    "                            #denom = 1*np.exp(-(i-j)**2/(2*sigma**2))+mu\n",
    "                            scores[j] += score/(denom[i]+mu)\n",
    "                            score = 0\n",
    "                        if kernel == 'Passage':\n",
    "                            score = passage_kernel(i,j,sigma)+mu*(collection_frequencies[doc_token_ids[i]]/total_terms)\n",
    "                            #denom = 1*np.exp(-(i-j)**2/(2*sigma**2))+mu\n",
    "                            scores[j] += score/(denom[i]+mu)\n",
    "                            score = 0\n",
    "    return max(scores)\n",
    "\n",
    "def plm_retrieval_tfidf_preselected():\n",
    "    data = {}\n",
    "    for key,value in validation_queries.items():\n",
    "        print(key,value)\n",
    "        for int_doc_id in query_1000_dict[key]:\n",
    "            external_document_id,_ = index.document(int_doc_id)\n",
    "            score = plm(int_doc_id,validation_queries[key],'Gaussian',collection_frequencies,0)\n",
    "            if key in data.keys():\n",
    "                data[key].append((tuple([float(score),str(external_document_id)])))\n",
    "            else:\n",
    "                data[key] =[((tuple([float(score),str(external_document_id)])))]\n",
    "\n",
    "    run_out_path = '{}.run'.format('plm')\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name='plm',\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "\n",
    "plm_retrieval_tfidf_preselected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plm_subprocess(plm_dict_all, plm_dict_avg, kernel, mu):\n",
    "    run_retrieval('plm', plm, kernel, mu)\n",
    "    shutil.move(\"./plm.run\", \"./trec_eval/plm.run\")\n",
    "    proc1 = Popen ('./plm.sh',shell=True,stdout = PIPE)\n",
    "    out, err = proc1.communicate()\n",
    "    var = out.decode('utf-8').split('\\t')\n",
    "    results = []\n",
    "    for v in var:\n",
    "        if v[:2] == '0.':\n",
    "            results.append(float(v[:6]))\n",
    "    name = kernel+\"-\"+str(mu)\n",
    "    plm_dict_all[name] = results[:-1]\n",
    "    plm_dict_avg[name] = results[-1]\n",
    "    os.remove(\"./trec_eval/plm.run\")\n",
    "    return plm_dict_all , plm_dict_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_plm_data():\n",
    "    plm_mu = np.arange(0,2200,200)\n",
    "    kernels = [\"Gaussian\", \"Triangle\", \"Hamming\", \"Circle\", \"Passage\"]\n",
    "    plm_dict_all = {}\n",
    "    plm_dict_avg = {}\n",
    "\n",
    "    for mu in plm_mu:\n",
    "        for kernel in kernels:\n",
    "            print(\"Evaluating the PLM model for a \",kernel,\" kernel and a mu of: \",mu)\n",
    "            plm_dict_all, plm_dict_avg = plm_subprocess(plm_dict_all, plm_dict_avg, kernel, mu)\n",
    "            with open('plm_dict_all.pickle', 'wb') as handle:\n",
    "                pickle.dump(plm_dict_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            with open('plm_dict_avg.pickle', 'wb') as handle:\n",
    "                pickle.dump(plm_dict_avg, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCxiFoIgCMKwiFkIgiAIw/L/Afh+y7OlQc+BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3181097160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('Pickle/plm_dict_avg.pickle', 'rb') as handle:\n",
    "    plm_dict_avg = pickle.load(handle)\n",
    "mu_dict = {}\n",
    "avg_dict = {}\n",
    "for key, value in plm_dict_avg.items():\n",
    "    key_split = key.split('-')\n",
    "    try:\n",
    "        mu_dict[key_split[0]].append(key_split[1])\n",
    "        avg_dict[key_split[0]].append(value)\n",
    "    except:\n",
    "        mu_dict[key_split[0]] = [key_split[1]]\n",
    "        avg_dict[key_split[0]] = [value]\n",
    "\n",
    "mu_template = [0, 200, 400, 600, 800]\n",
    "for key, value in avg_dict.items():\n",
    "    mu = mu_dict[key]\n",
    "    val = []\n",
    "    for m in mu_template:\n",
    "        idx = mu.index(str(m))\n",
    "        val.append(value[idx])  \n",
    "    plt.plot(mu_template, val, label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('NDCG@10')\n",
    "plt.xlabel('Smoothing factor mu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresults_dict = {}\\nrun_retrieval(\\'tfidf\\', tfidf)\\nresults_dict = results_subprocess(\\'tfidf\\', results_dict)\\nprint(results_dict)\\n\\nrun_retrieval(\\'BM25\\', BM25)\\nresults_dict = results_subprocess(\\'BM25\\', results_dict)\\n\\nrun_retrieval(\\'JelinekMercer\\', JelinekMercer)\\nresults_dict = results_subprocess(\\'JelinekMercer\\', results_dict)\\n\\nrun_retrieval(\\'Dirichlet\\', Dirichlet)\\nresults_dict = results_subprocess(\\'Dirichlet\\', results_dict)\\n\\nrun_retrieval(\\'AbsoluteDiscounting\\', AbsoluteDiscounting)\\nresults_dict = results_subprocess(\\'AbsoluteDiscounting\\', results_dict)\\n\\nrun_retrieval(\\'plm\\', plm, \"Triangle\", 0)\\nresults_dict = results_subprocess(\\'plm\\', results_dict)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_subprocess(model_name, results_dict):\n",
    "    \"\"\"\n",
    "    This function is used to generate the run files we used to be able to do significane testing.\n",
    "    Since this takes hours, we included the run files themselves as well as pickle dump files\n",
    "    so that you are able to recreate the data if necessary\n",
    "    \"\"\"\n",
    "    file_orig = \"./\"+model_name+\".run\"\n",
    "    shutil.move(file_orig, \"./trec_eval/results.run\")\n",
    "    proc1 = Popen ('./results.sh',shell=True,stdout = PIPE)\n",
    "    out, err = proc1.communicate()\n",
    "    var = out.decode('utf-8').split('\\n')\n",
    "    for v in var:\n",
    "        split = v.split('\\t')\n",
    "        if len(split) == 3 and split[1] != 'all':\n",
    "            try:\n",
    "                results_dict[(model_name, split[0].strip())].append(float(split[2]))\n",
    "            except:\n",
    "                results_dict[(model_name, split[0].strip())] = [float(split[2])]\n",
    "    os.remove(\"./trec_eval/results.run\")\n",
    "    with open('results_dict.pickle', 'wb') as handle:\n",
    "            pickle.dump(results_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return results_dict\n",
    "\"\"\"\n",
    "results_dict = {}\n",
    "run_retrieval('tfidf', tfidf)\n",
    "results_dict = results_subprocess('tfidf', results_dict)\n",
    "print(results_dict)\n",
    "\n",
    "run_retrieval('BM25', BM25)\n",
    "results_dict = results_subprocess('BM25', results_dict)\n",
    "\n",
    "run_retrieval('JelinekMercer', JelinekMercer)\n",
    "results_dict = results_subprocess('JelinekMercer', results_dict)\n",
    "\n",
    "run_retrieval('Dirichlet', Dirichlet)\n",
    "results_dict = results_subprocess('Dirichlet', results_dict)\n",
    "\n",
    "run_retrieval('AbsoluteDiscounting', AbsoluteDiscounting)\n",
    "results_dict = results_subprocess('AbsoluteDiscounting', results_dict)\n",
    "\n",
    "run_retrieval('plm', plm, \"Triangle\", 0)\n",
    "results_dict = results_subprocess('plm', results_dict)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking significance of all results with alpha equal to 0.0008545229269492083\n",
      "T-test on Dirichlet and AbsoluteDiscounting with recall_1000 gave a significant difference with a p-value of 0.000404\n",
      "The means of these models and this metric are  0.594366666667 for Dirichlet and 0.64242 for AbsoluteDiscounting\n"
     ]
    }
   ],
   "source": [
    "with open('Pickle/results_dict.pickle', 'rb') as handle:\n",
    "    data_dict = pickle.load(handle)\n",
    "\n",
    "def check_significance(a):\n",
    "    \"\"\"\"\n",
    "    Check significane of all models using a t-test. The alpha parameter specifies the alpha value used.\n",
    "    1 is used for an alpha of 0.05, 2 for Bonferroni correction and 3 for Sidak correction.\n",
    "    \"\"\"\n",
    "    models = ['JelinekMercer','tfidf','BM25','Dirichlet','AbsoluteDiscounting','plm']\n",
    "    metrics = ['P_5','ndcg_cut_10','map','recall_1000']\n",
    "    tested = []\n",
    "        \n",
    "    alpha = 0.05\n",
    "    m = 60.0\n",
    "    \n",
    "    if a == 1:\n",
    "        alpha = 0.05\n",
    "    elif a == 2:\n",
    "        alpha = alpha/m #Bonferroni correction\n",
    "    elif a == 3:\n",
    "        alpha = 1-(1-alpha)**(1/m) #Å idÃ¡k correction\n",
    "\n",
    "    print(\"Checking significance of all results with alpha equal to\", alpha)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        for model1 in models:\n",
    "            for model2 in models:\n",
    "                if model1 != model2 and (model1,model2,metric) not in tested and (model2,model1,metric) not in tested:\n",
    "                    t_test = stats.ttest_rel(data_dict[(model1,metric)], data_dict[(model2,metric)])\n",
    "                    tested.append((model1,model2,metric))\n",
    "                    tested.append((model2,model1,metric))\n",
    "                    if t_test[1] < alpha:\n",
    "                        print('T-test on %s and %s with %s gave a significant difference with a p-value of %f' % (model1,model2,metric,t_test[1]))\n",
    "                        print('The means of these models and this metric are ', np.mean(data_dict[(model1,metric)]), 'for', model1, 'and' , np.mean(data_dict[(model2,metric)]), 'for', model2)\n",
    "check_significance(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyse the results of the t-tests conducted. When we not correct for the multiple-comparison problem we see a lot of significant results. However, when we do control for it using both Sidak an Bonferroni correction we see only one significant difference. This is with two langauge models one using Dirichlet smoothing and the other absolute discounting using the recall at 1000 evaluation metric. When we look at the values, we see that the model using absolute discounting is significantly better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'queries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d7973e54e509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#First we have a look at the most significant difference between the models as found above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalid_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_query_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalid_queries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'queries' is not defined"
     ]
    }
   ],
   "source": [
    "#First we have a look at the most significant difference between the models as found above.\n",
    "valid_queries = []\n",
    "for query_id, query_text in queries.items():\n",
    "    if query_id in valid_query_ids:\n",
    "        valid_queries.append(query_text)\n",
    "        \n",
    "def find_query_length_difference(model_metric_1,model_metric_2):\n",
    "\n",
    "    length = 0  \n",
    "    for query in valid_queries:\n",
    "        length += len(query.split())\n",
    "    print(\"Average query length is \",(length/len(valid_queries)))\n",
    "\n",
    "    difference = []\n",
    "    for i in range(0,len(model_metric_1)):\n",
    "        difference.append(model_metric_1[i]-model_metric_2[i])\n",
    "\n",
    "    average_difference = np.mean(difference)\n",
    "    length1 = []\n",
    "    length2 = []\n",
    "    for i in range(0,len(difference)):\n",
    "        if difference[i] > average_difference:\n",
    "            length1.append(len(valid_queries[i].split()))\n",
    "        elif difference[i] < average_difference:\n",
    "            length2.append(len(valid_queries[i].split()))\n",
    "    print('Average length of queries where model1 outperofrms model2 :',  np.mean(length1))\n",
    "    print('Average length of queries where model2 outperofrms model1 :',  np.mean(length2))\n",
    " \n",
    "\n",
    "def query_word_occurences(model_metric_1,model_metric_2):\n",
    "    splitted_queries = []\n",
    "    difference = []\n",
    "    length1 = []\n",
    "    length2 = []\n",
    "    for query_id, query in queries.items():\n",
    "        if query_id in valid_query_ids:\n",
    "            splitted_queries.append(list(query.split()))\n",
    "    query_occurences = []\n",
    "    for q in splitted_queries:\n",
    "        total_terms = 0\n",
    "        for word in q:\n",
    "            if word.lower() in token2id:\n",
    "                total_terms += collection_frequencies[token2id[word.lower()]]\n",
    "        query_occurences.append(total_terms/len(q))\n",
    "    \n",
    "    for i in range(0,len(model_metric_1)):\n",
    "        difference.append(model_metric_1[i]-model_metric_2[i])\n",
    "    average_difference = np.mean(difference)\n",
    "\n",
    "    for i in range(0,len(difference)):\n",
    "        if difference[i] > average_difference:\n",
    "            length1.append(query_occurences[i])\n",
    "        elif difference[i] < average_difference:\n",
    "            length2.append(query_occurences[i])\n",
    "\n",
    "    print('Average number of occurences of query words where model1 outperofrms model2 :',  np.mean(length1))\n",
    "    print('Average number of occurences of query words when model2 outperofrms model1 :',  np.mean(length2))\n",
    "    \n",
    "print(\"Function call 1\")  \n",
    "find_query_length_difference(data_dict[('BM25','ndcg_cut_10')],data_dict[('tfidf','ndcg_cut_10')])\n",
    "print('\\n')\n",
    "print(\"Function call 2-5\")  \n",
    "find_query_length_difference(data_dict[('BM25','ndcg_cut_10')],data_dict[('Dirichlet','ndcg_cut_10')])\n",
    "find_query_length_difference(data_dict[('BM25','ndcg_cut_10')],data_dict[('JelinekMercer','ndcg_cut_10')])\n",
    "find_query_length_difference(data_dict[('BM25','ndcg_cut_10')],data_dict[('AbsoluteDiscounting','ndcg_cut_10')])\n",
    "find_query_length_difference(data_dict[('BM25','ndcg_cut_10')],data_dict[('plm','ndcg_cut_10')])\n",
    "print(\"\\n\")\n",
    "print(\"Function call 6\")\n",
    "find_query_length_difference(data_dict[('plm','ndcg_cut_10')],data_dict[('JelinekMercer','ndcg_cut_10')])\n",
    "print(\"\\n\")\n",
    "print(\"Function call 7-9\")\n",
    "query_word_occurences(data_dict[('BM25','ndcg_cut_10')],data_dict[('plm','ndcg_cut_10')])\n",
    "query_word_occurences(data_dict[('BM25','ndcg_cut_10')],data_dict[('AbsoluteDiscounting','ndcg_cut_10')])\n",
    "query_word_occurences(data_dict[('tfidf','ndcg_cut_10')],data_dict[('plm','ndcg_cut_10')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query length\n",
    "#### Function call 1:\n",
    "The difference in average query length when one model wins for BM25 and TFIDF and NDCG@10 we see that BM25 is better at longer queries. This is line with expectation since this model normalizes for query length. \n",
    "\n",
    "#### Function call 2-5:\n",
    "Here we see that language models outperform BM25 on longer queries. We are not entirely sure why this is the case, but we think this is caused by the fact that langauge models profit from more words since it becomes better at estimating the probabilities while this does not hold for BM25.\n",
    "\n",
    "#### Function call 6:\n",
    "Here we see that the positional language model works better for longer queries compared with the language model using Dirichlet smoothing. When a query only contains one word, the added value of PLM vanishes and it simply is a check whether the word occurs in a document. The longer a query gets, the more added value the PLM adds using its kernel.\n",
    "\n",
    "\n",
    "### Occurences of query words in text\n",
    "#### Function call 7-9:\n",
    "Here we see that langauge models outperform BM25 whenever the number of occurences of the query terms in the documents is relatively high. This is in line with expectations, since these models need a lot of evidence in order to determine the (correct) probabilities of word sequences. While BM25 does not need this and therefore outperform langauge models when we have query terms that are relatively unique (do not occur very often in the collection of documents). Also interesting is that this does not hold for the TFIDF model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Latent Semantic Models (LSMs) [15 points] ###\n",
    "\n",
    "In this task you will experiment with applying distributional semantics methods ([LSI](http://lsa3.colorado.edu/papers/JASIS.lsi.90.pdf) **[5 points]** and [LDA](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf) **[5 points]**) for retrieval.\n",
    "\n",
    "You do not need to implement LSI or LDA on your own. Instead, you can use [gensim](http://radimrehurek.com/gensim/index.html). An example on how to integrate Pyndri with Gensim for word2vec can be found [here](https://github.com/cvangysel/pyndri/blob/master/examples/word2vec.py). For the remaining latent vector space models, you will need to implement connector classes (such as `IndriSentences`) by yourself.\n",
    "\n",
    "In order to use a latent semantic model for retrieval, you need to:\n",
    "   * build a representation of the query **q**,\n",
    "   * build a representation of the document **d**,\n",
    "   * calculate the similarity between **q** and **d** (e.g., cosine similarity, KL-divergence).\n",
    "     \n",
    "The exact implementation here depends on the latent semantic model you are using. \n",
    "   \n",
    "Each of these LSMs come with various hyperparameters to tune. Make a choice on the parameters, and explicitly mention the reasons that led you to these decisions. You can use the validation set to optimize hyper parameters you see fit; motivate your decisions. In addition, mention clearly how the query/document representations were constructed for each LSM and explain your choices.\n",
    "\n",
    "In this experiment, you will first obtain an initial top-1000 ranking for each query using TF-IDF in **Task 1**, and then re-rank the documents using the LSMs. Use TREC Eval to obtain the results and report on `NDCG@10`, Mean Average Precision (`MAP@1000`), `Precision@5` and `Recall@1000`.\n",
    "\n",
    "Perform significance testing **[5 points]** (similar as in Task 1) in the class of semantic matching methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper cell, that returns two dictionaries. These dictionaries can be used to convert \n",
    "# docIDs to external docIDs. Internal docIDS are 1,2,3,...,164597\n",
    "# external docIDs are AP-XXXXXX-XXXX\n",
    "\n",
    "ext2int_ids = {}\n",
    "int2ext_ids = {}\n",
    "        \n",
    "for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "    ext_doc_id, _ = index.document(int_doc_id)\n",
    "    ext2int_ids[ext_doc_id] = int_doc_id\n",
    "    int2ext_ids[int_doc_id] = ext_doc_id\n",
    "    \n",
    "#print (int2ext_ids[1])\n",
    "#print (ext2int_ids['AP890425-0001'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the model\n",
    "Training is done by creating a very large BOW representation for all the documents in the collection. These models are saved, so training has to be done only once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that returns a BOW representation of the entire document set (160k documents)\n",
    "# It loops through al the documents, and appends them to a list\n",
    "# RETURNS\n",
    "# - bow representation of the corpus\n",
    "# - token2id, a dictionary for converting tokens (words) to ids\n",
    "# - id2token, another dictionary for converting ids to words (tokens)\n",
    "\n",
    "def document_bow():\n",
    "    dictionary = pyndri.extract_dictionary(index) \n",
    "    token2id, id2token, _ = index.get_dictionary() # Only id2token is necessary\n",
    "    documents_list = [] # The list that all the documents will be appended to\n",
    "    \n",
    "    for i in range(1,num_documents+1):\n",
    "        _ , doc = index.document(i)\n",
    "        doc = [id2token[word_id] for word_id in doc if word_id > 0]\n",
    "        documents_list.append(doc)\n",
    "        \n",
    "    bow_corpus = [dictionary.doc2bow(text) for text in documents_list]\n",
    "    return bow_corpus, token2id, id2token\n",
    "\n",
    "corpus, token2id, id2token = document_bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LDA_LSI():\n",
    "    # Train LDA-model\n",
    "    num_topics = 20\n",
    "    lda20 = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word = id2token, passes=10)\n",
    "    lda20.save('LDAmodels/LDA20')\n",
    "\n",
    "    # Train LSI-model\n",
    "    num_topics = 250\n",
    "    lsi250 = gensim.models.lsimodel.LsiModel(corpus=corpus, id2word=id2token, num_topics=num_topics)\n",
    "    lsi250.save('LSImodels/LSI250')\n",
    "\n",
    "    num_topics = 500\n",
    "    lsi500 = gensim.models.lsimodel.LsiModel(corpus=corpus, id2word=id2token, num_topics=num_topics)\n",
    "    lsi100.save('LSImodels/LSI500')\n",
    "\n",
    "    num_topics = 1000\n",
    "    lsi1000 = gensim.models.lsimodel.LsiModel(corpus=corpus, id2word=id2token, num_topics=num_topics)\n",
    "    lsi1000.save('LSImodels/LSI1000')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that returns a document given an external doc_id\n",
    "# INPUT\n",
    "# - an internal doc_id, a string, for instance: APXXXXX-XX\n",
    "# RETURNS\n",
    "# - an list of strings representing a text, for instance ['joris','is','de','beste']\n",
    "def get_document(doc_id):\n",
    "    int_doc_id = ext2int_ids[doc_id]\n",
    "    _,text_ids = index.document(int_doc_id)\n",
    "    return [id2token[word_id] for word_id in text_ids if word_id > 0]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that removes punctuation, and lowers a query\n",
    "# INPUT\n",
    "# - a list of strings, the query, for instance ['Airbus','Subsidies']\n",
    "# - token2id, a dictionary converting words to ids\n",
    "# RETURNS\n",
    "# - the same query lowercased without punctuation\n",
    "def remove_punctuation(query,token2id):\n",
    "    \n",
    "    punctuation_list = ['\"', '(',')', '&','-',\"'\",'.','/','?']\n",
    "        \n",
    "    good_query = []\n",
    "    for word in query:           \n",
    "        \n",
    "        good_word = \"\"\n",
    "        if len(word) == 1 and word in punctuation_list:\n",
    "            if word == '&':\n",
    "                good_query.append('and')\n",
    "            else:\n",
    "                continue\n",
    "        elif word == 'vs' or word == 'vs.':\n",
    "            good_query.append('versus')\n",
    "        elif word == 'us' or word == 'U.S.' or word == \"U.S.'s\" or word == 'U.':\n",
    "            good_query.append('united')\n",
    "            good_query.append('states')\n",
    "        else:\n",
    "            for letter in word:\n",
    "                if letter not in punctuation_list:\n",
    "                    good_word += letter.lower()\n",
    "                elif letter == '-' or letter == \"'\" or letter == '/':\n",
    "                    good_query.append(good_word)\n",
    "                    good_word = \"\"\n",
    "            else:\n",
    "                good_query.append(good_word)\n",
    "        \n",
    "    if 'us' in good_query: # Replace 'us' with 'united','states'\n",
    "        place = good_query.index('us')\n",
    "        good_query.pop(int(place))\n",
    "        good_query.insert(int(place),'united')\n",
    "        good_query.insert(int(place) + 1 , 'states')\n",
    "       \n",
    "    \n",
    "    best_query = []\n",
    "    for word in good_query:\n",
    "        if word in token2id and len(word) > 1:\n",
    "            best_query.append(word)\n",
    "    \n",
    "    return best_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that takes returns a list of indices, converting a text into indices\n",
    "# INPUT\n",
    "# - a list of strings, for instance ['python','wizard']\n",
    "# RETURNS\n",
    "# - a list of IDS, for instance [1,2] where 'python' maps to 1, and 'wizard' maps to 2\n",
    "# according to the token2id dictionary\n",
    "def text_to_ind(text):\n",
    "    token_ids = [token2id[token] for token in text if token in token2id] \n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that generates the topic vector from a text. This can be a document or a query\n",
    "# INPUT\n",
    "# - a text, a list of strings, for instance ['python','wizard']\n",
    "# - a model, either LSI or LDA model\n",
    "# RETURNS \n",
    "# - a topic scores vector, with scores\n",
    "def topic_vector_from_text(text,model):\n",
    "    #random.shuffle(text) # randomly shuffle text, to really create a BOW\n",
    "    bow_ids = text_to_ind(text)\n",
    "    bow_ids_counter = collections.Counter(bow_ids)\n",
    "    bow_list = [[key,value] for key,value in bow_ids_counter.items()]\n",
    "    topics_scores = model[bow_list] # topics_scores is of type: [ (1,score1),(2,score2),etc,etc]\n",
    "    \n",
    "    topic_ids = [topic_id for topic_id,score in topics_scores]\n",
    "    topic_scores = [score for topic_id,score in topics_scores]\n",
    "    num_topics = model.num_topics\n",
    "    \n",
    "    scores = np.zeros(num_topics)\n",
    "    scores[topic_ids] = topic_scores\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that calculates the cosine similarity between two vectors\n",
    "# INPUT\n",
    "# - query_topic_vec, the query topic vector\n",
    "# - doc_topic_vec, the document topic vector\n",
    "# RETURNS\n",
    "# - the cosine similarity between query_vec and doc_vec, a float\n",
    "def check_similarity(query_topic_vec,doc_topic_vec):\n",
    "    return ssd.cosine(query_topic_vec,doc_topic_vec)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that scores a list of document-ids based on a LSI or LDA model\n",
    "# INPUT\n",
    "# - a model, this can be either a LSI or LDA model\n",
    "# - a query, this is a list of strings, in the form ['python','wizard']\n",
    "# - a list of doc_ids, of the form [APXXXXX-XX,APYYYYY-YY, etc, etc]. This list is probably of length 1000\n",
    "# RETURNS\n",
    "# - a list of the 1000 documents, a list of form [(APYYYYY-YY,scoreY),(APXXXXX-XX,scoreX),(etc,score_etc),...],\n",
    "# , where the first element of the list is the best query result, and the last element of the list is the worst \n",
    "def lsi_lda_model_score(model,query,doc_ids):\n",
    "    query_topic_vec = topic_vector_from_text(query,model)    \n",
    "    \n",
    "    ranking = []\n",
    "    \n",
    "    for ext_doc_ID in doc_ids:\n",
    "        doc = get_document(ext_doc_ID) # returns the document in text\n",
    "        doc_topic_vec = topic_vector_from_text(doc,model)\n",
    "        score = check_similarity(query_topic_vec,doc_topic_vec)\n",
    "        ranking.append((ext_doc_ID,score))\n",
    "        \n",
    "    ranking.sort(key=itemgetter(1))\n",
    "    \n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function that reads the tfidf.run file\n",
    "# INPUT\n",
    "# - filename, a string\n",
    "# RETURNS\n",
    "# - a dictionary with takes a query_id (51,200) as value, and returns a list of a 1000 documents [APXXXX-XX,etc,...]\n",
    "def read_tfidf_file(filename):\n",
    "    \n",
    "    return_dict = defaultdict(list)\n",
    "    \n",
    "    # Fill the dictionary with empty lists:\n",
    "    # Queries go from 51 to 200\n",
    "    #for i, qid in enumerate(queries):\n",
    "     #   return_dict[int(qid)] = []\n",
    "      #  print (qid)\n",
    "        \n",
    "    for qid in valid_query_ids:\n",
    "        return_dict[int(qid)] = []\n",
    "    \n",
    "    with open(filename,'r') as fn:\n",
    "        for line in fn:\n",
    "            query_id = int(line.split()[0])\n",
    "            ext_doc_ID = line.split()[2]\n",
    "            \n",
    "            return_dict[query_id].append(ext_doc_ID) \n",
    "            \n",
    "    return return_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A functions that appends data to a big data list\n",
    "# INPUT\n",
    "# - a list to_be_added, of the form [(APYYYYY-YY,scoreY),(APXXXXX-XX,scoreX),(etc,score_etc),...]\n",
    "# - queryID, an integer\n",
    "# - model_name a str with the model name\n",
    "# - a data list of lists within a list, in which to add to_be_added\n",
    "# - the lists within the list are of the form [queryID,'Q0',exc_doc_ID,rank,score,'modelname']\n",
    "# RETURNS\n",
    "# - data_list a list of list. Each list in the list is of the form [queryID,'Q0',ext_doc_ID,rank,score,model_name] \n",
    "def append_data(to_be_added,query_id,model_name,data_list):\n",
    "    for i in range(0,len(to_be_added)):\n",
    "        temp_list = []\n",
    "        temp_list.append(query_id)\n",
    "        temp_list.append('Q0')\n",
    "        temp_list.append(to_be_added[i][0])\n",
    "        temp_list.append(i+1) # rank\n",
    "        temp_list.append(to_be_added[i][1])\n",
    "        temp_list.append(model_name)\n",
    "        data_list.append(temp_list)\n",
    "    return data_list         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that writes the data to a file\n",
    "# INPUT\n",
    "# - model_name, a string of the desired name of the output file\n",
    "# - data, a list of list. Each list in the list is of the form [queryID,'Q0',ext_doc_ID,rank,score,model_name]\n",
    "# RETURNS\n",
    "# - writes data to a file, returns a file in the same folder as the .ipynb notebook\n",
    "def write_model(model_name,data):\n",
    "    with open(model_name,'w') as mn:\n",
    "        for row in data:\n",
    "            for term in row:\n",
    "                mn.write(str(term) + ' ')\n",
    "            mn.write('\\n')\n",
    "    mn.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA20.runfile created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./trec_eval/LDA20.run'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_run_file(model_name,model):\n",
    "\n",
    "    query_return_dict = read_tfidf_file('RunFiles/tfidf_valid.run')\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for query,values in query_return_dict.items():\n",
    "        query_in_text = queries[str(query)].lower().split()\n",
    "        \n",
    "        query_in_text = remove_punctuation(query_in_text,token2id)\n",
    "        \n",
    "        new_ranking = lsi_lda_model_score(model,query_in_text,query_return_dict[query])\n",
    "        data = append_data(new_ranking,int(query),model_name,data)\n",
    "    \n",
    "    write_model(model_name,data)\n",
    "    print (model_name+'file created!')\n",
    "    return\n",
    "\n",
    "model = gensim.models.ldamodel.LdaModel.load('LDAmodels/LDA20')\n",
    "#model = gensim.models.lsimodel.LsiModel.load('LSImodels/LSI250')\n",
    "model_name = 'LDA20.run'\n",
    "\n",
    "create_run_file(model_name,model)\n",
    "shutil.move('./'+model_name,'./trec_eval/'+model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(model_name):\n",
    "    '''\n",
    "    A function that writes the result to a text file\n",
    "    INPUT\n",
    "    - a model_name, this can be LSI50, LSI100, LSI250, LDA10 or LDA20 or another string\n",
    "    RETURNS\n",
    "    - a .txt file in the folder results. Each line contains the model, the query id, and the score\n",
    "    \n",
    "    '''\n",
    "    import shutil\n",
    "    output_file_name = 'results'+model_name+'.txt'\n",
    "    \n",
    "    command = './eval'+model_name + '.sh'\n",
    "    \n",
    "    shell_name = 'eval'+model_name+'.sh'\n",
    "\n",
    "    shutil.move('./ShellScripts/'+shell_name,'./'+shell_name)\n",
    "    \n",
    "    with open('Results/'+output_file_name,'w') as file:\n",
    "        \n",
    "        proc = Popen (command,shell=True,stdout = PIPE)\n",
    "        out,err = proc.communicate()\n",
    "        \n",
    "        result_list = out.decode('utf-8').split('\\n')\n",
    "        for result in result_list:\n",
    "            line = result.split('\\t')\n",
    "            \n",
    "            write_list = []\n",
    "            \n",
    "            for i in line:\n",
    "                write_list.append(str(i))\n",
    "                file.write(write_list[-1] + ' ')\n",
    "            file.write('\\n')\n",
    "        file.close()\n",
    "        \n",
    "    shutil.move('./'+shell_name,'./ShellScripts/'+shell_name) # move it back\n",
    "\n",
    "    return\n",
    "    \n",
    "#write_results('LSI10')\n",
    "#write_results('LSI50')\n",
    "#write_results('LSI100')\n",
    "#write_results('LSI250')\n",
    "#write_results('LDA10')\n",
    "#write_results('LDA20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Results/resultsLSI50.txt','r') as lsi50:\n",
    "    \n",
    "    map_scores_lsi50 = []\n",
    "    p5_scores_lsi50 = []\n",
    "    recall1000_scores_lsi50 = []\n",
    "    ndcg10_scores_lsi50 = []\n",
    "    \n",
    "    for line in lsi50.readlines():\n",
    "        result_line = line.split()\n",
    "        if result_line != []:\n",
    "            if result_line[0] == 'map' and result_line[1] != 'all' and result_line != []:\n",
    "                map_scores_lsi50.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'P_5' and result_line[1] != 'all':\n",
    "                p5_scores_lsi50.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'recall_1000' and result_line[1] != 'all':\n",
    "                recall1000_scores_lsi50.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'ndcg_cut_10' and result_line[1] != 'all':\n",
    "                ndcg10_scores_lsi50.append(float(result_line[-1]))\n",
    "\n",
    "with open('Results/resultsLSI250.txt','r') as lsi250:\n",
    "        \n",
    "    map_scores_lsi250 = []\n",
    "    p5_scores_lsi250 = []\n",
    "    recall1000_scores_lsi250 = []\n",
    "    ndcg10_scores_lsi250 = []\n",
    "    \n",
    "    for line in lsi250.readlines():\n",
    "        result_line = line.split()\n",
    "        if result_line != []:\n",
    "            if result_line[0] == 'map' and result_line[1] != 'all' and result_line != []:\n",
    "                map_scores_lsi250.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'P_5' and result_line[1] != 'all':\n",
    "                p5_scores_lsi250.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'recall_1000' and result_line[1] != 'all':\n",
    "                recall1000_scores_lsi250.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'ndcg_cut_10' and result_line[1] != 'all':\n",
    "                ndcg10_scores_lsi250.append(float(result_line[-1]))\n",
    "            \n",
    "with open('Results/resultsLDA20.txt','r') as lda20:\n",
    "        \n",
    "    map_scores_lda20 = []\n",
    "    p5_scores_lda20 = []\n",
    "    recall1000_scores_lda20 = []\n",
    "    ndcg10_scores_lda20 = []\n",
    "    \n",
    "    for line in lda20.readlines():\n",
    "        result_line = line.split()\n",
    "        if result_line != []:\n",
    "            if result_line[0] == 'map' and result_line[1] != 'all' and result_line != []:\n",
    "                map_scores_lda20.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'P_5' and result_line[1] != 'all':\n",
    "                p5_scores_lda20.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'recall_1000' and result_line[1] != 'all':\n",
    "                recall1000_scores_lda20.append(float(result_line[-1]))\n",
    "            elif result_line[0] == 'ndcg_cut_10' and result_line[1] != 'all':\n",
    "                ndcg10_scores_lda20.append(float(result_line[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking significance of all results with alpha equal to 0.0008545229269492083\n",
      "T-test on lda20 and lsi250 with P_5 gave a p-value of nan\n",
      "T-test on lda20 and lsi50 with P_5 gave a p-value of nan\n",
      "T-test on lsi250 and lsi50 with P_5 gave a p-value of nan\n",
      "T-test on lda20 and lsi250 with ndcg_cut_10 gave a p-value of nan\n",
      "T-test on lda20 and lsi50 with ndcg_cut_10 gave a p-value of nan\n",
      "T-test on lsi250 and lsi50 with ndcg_cut_10 gave a p-value of nan\n",
      "T-test on lda20 and lsi250 with map gave a p-value of nan\n",
      "T-test on lda20 and lsi50 with map gave a p-value of nan\n",
      "T-test on lsi250 and lsi50 with map gave a p-value of nan\n",
      "T-test on lda20 and lsi250 with recall_1000 gave a p-value of nan\n",
      "T-test on lda20 and lsi50 with recall_1000 gave a p-value of nan\n",
      "T-test on lsi250 and lsi50 with recall_1000 gave a p-value of nan\n"
     ]
    }
   ],
   "source": [
    "#Test significance of results\n",
    "data_dict[('lsi50','map')] = map_scores_lsi50\n",
    "data_dict[('lsi50','P_5')] = p5_scores_lsi50\n",
    "data_dict[('lsi50','recall_1000')] = recall1000_scores_lsi50\n",
    "data_dict[('lsi50','ndcg_cut_10')] = ndcg10_scores_lsi50\n",
    "\n",
    "data_dict[('lsi250','map')] = map_scores_lsi250\n",
    "data_dict[('lsi250','P_5')] = p5_scores_lsi250\n",
    "data_dict[('lsi250','recall_1000')] = recall1000_scores_lsi250\n",
    "data_dict[('lsi250','ndcg_cut_10')]= ndcg10_scores_lsi250\n",
    "\n",
    "data_dict[('lda20','map')] = map_scores_lda20\n",
    "data_dict[('lda20','P_5')] = p5_scores_lda20\n",
    "data_dict[('lda20','recall_1000')]= recall1000_scores_lda20\n",
    "data_dict[('lda20','ndcg_cut_10')]= ndcg10_scores_lda20\n",
    "\n",
    "def check_significance2(a):\n",
    "    \"\"\"\"\n",
    "    Check significane of all models using a t-test. The alpha parameter specifies the alpha value used.\n",
    "    1 is used for an alpha of 0.05, 2 for Bonferroni correction and 3 for Sidak correction.\n",
    "    \"\"\"\n",
    "    models = ['lda20','lsi250','lsi50']\n",
    "    metrics = ['P_5','ndcg_cut_10','map','recall_1000']\n",
    "    tested = []\n",
    "        \n",
    "    alpha = 0.05\n",
    "    m = 60.0\n",
    "    \n",
    "    if a == 1:\n",
    "        alpha = 0.05\n",
    "    elif a == 2:\n",
    "        alpha = alpha/m #Bonferroni correction\n",
    "    elif a == 3:\n",
    "        alpha = 1-(1-alpha)**(1/m) #Å idÃ¡k correction\n",
    "\n",
    "    print(\"Checking significance of all results with alpha equal to\", alpha)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        for model1 in models:\n",
    "            for model2 in models:\n",
    "                if model1 != model2 and (model1,model2,metric) not in tested and (model2,model1,metric) not in tested:\n",
    "                    t_test = stats.ttest_rel(data_dict[(model1,metric)], data_dict[(model2,metric)])\n",
    "                    tested.append((model1,model2,metric))\n",
    "                    tested.append((model2,model1,metric))\n",
    "                    print('T-test on %s and %s with %s gave a p-value of %f' % (model1,model2,metric,t_test[1]))\n",
    "check_significance2(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:  Word embeddings for ranking [20 points] (open-ended) ###\n",
    "\n",
    "First create word embeddings on the corpus we provided using [word2vec](http://arxiv.org/abs/1411.2738) -- [gensim implementation](https://radimrehurek.com/gensim/models/word2vec.html). You should extract the indexed documents using pyndri and provide them to gensim for training a model (see example [here](https://github.com/nickvosk/pyndri/blob/master/examples/word2vec.py)).\n",
    "   \n",
    "This is an open-ended task. It is left up you to decide how you will combine word embeddings to derive query and document representations. Note that since we provide the implementation for training word2vec, you will be graded based on your creativity on combining word embeddings for building query and document representations.\n",
    "\n",
    "Note: If you want to experiment with pre-trained word embeddings on a different corpus, you can use the word embeddings we provide alongside the assignment (./data/reduced_vectors_google.txt.tar.gz). These are the [google word2vec word embeddings](https://code.google.com/archive/p/word2vec/), reduced to only the words that appear in the document collection we use in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pyndri.extract_dictionary(index)\n",
    "sentences = pyndri.compat.IndriSentences(index, dictionary)\n",
    "\n",
    "word_vectors = gensim.models.Word2Vec.load('W2V/w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that makes and saves a w2v model\n",
    "def calculate_word2vec():\n",
    "    dictionary = pyndri.extract_dictionary(index)\n",
    "    sentences = pyndri.compat.IndriSentences(index, dictionary)\n",
    "\n",
    "    word2vec = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "    word2vec.save('W2V/w2v')\n",
    "    return\n",
    "\n",
    "# Function that load a w2v model\n",
    "def load_word2vec():\n",
    "    word_vectors = gensim.models.Word2Vec.load('W2V/w2v')\n",
    "    return word_vectors\n",
    "\n",
    "# A function that returns a vector representation of a word\n",
    "# INPUT\n",
    "# - a word, a string, like 'joris'\n",
    "# - word_vectors, a dictionary which returns the vector of a word\n",
    "# CODE\n",
    "# - returns the vector representation of a word. If this is not avalaible, it stems the word and finds the vector representation\n",
    "# RETURNS\n",
    "# - the vector representation of the (stemmed) word\n",
    "def get_vector_for_word(word,word_vectors):\n",
    "    try:\n",
    "        embedding = word_vectors[str(word)]\n",
    "        return embedding\n",
    "    except KeyError:\n",
    "        stemmed_word = PorterStemmer().stem(str(word))\n",
    "        return word_vectors[stemmed_word]\n",
    "\n",
    "# Function that removes punctuation, and lowers a query\n",
    "# INPUT\n",
    "# - a list of strings, the query, for instance ['Airbus','Subsidies']\n",
    "# - token2id, a dictionary converting words to ids\n",
    "# RETURNS\n",
    "# - the same query lowercased without punctuation\n",
    "def remove_punctuation(query,token2id):\n",
    "    \n",
    "    punctuation_list = ['\"', '(',')', '&','-',\"'\",'.','/','?']\n",
    "        \n",
    "    good_query = []\n",
    "    for word in query:           \n",
    "        \n",
    "        good_word = \"\"\n",
    "        if len(word) == 1 and word in punctuation_list:\n",
    "            if word == '&':\n",
    "                good_query.append('and')\n",
    "            else:\n",
    "                continue\n",
    "        elif word == 'vs' or word == 'vs.':\n",
    "            good_query.append('versus')\n",
    "        elif word == 'us' or word == 'U.S.' or word == \"U.S.'s\" or word == 'U.':\n",
    "            good_query.append('united')\n",
    "            good_query.append('states')\n",
    "        else:\n",
    "            for letter in word:\n",
    "                if letter not in punctuation_list:\n",
    "                    good_word += letter.lower()\n",
    "                elif letter == '-' or letter == \"'\" or letter == '/':\n",
    "                    good_query.append(good_word)\n",
    "                    good_word = \"\"\n",
    "            else:\n",
    "                good_query.append(good_word)\n",
    "        \n",
    "    if 'us' in good_query: # Replace 'us' with 'united','states'\n",
    "        place = good_query.index('us')\n",
    "        good_query.pop(int(place))\n",
    "        good_query.insert(int(place),'united')\n",
    "        good_query.insert(int(place) + 1 , 'states')\n",
    "       \n",
    "    \n",
    "    best_query = []\n",
    "    for word in good_query:\n",
    "        if word in token2id and len(word) > 1:\n",
    "            best_query.append(word)\n",
    "    \n",
    "    return best_query\n",
    "\n",
    "def get_document(doc_id):\n",
    "    int_doc_id = ext2int_ids[doc_id]\n",
    "    _,text_ids = index.document(int_doc_id)\n",
    "    return [id2token[word_id] for word_id in text_ids if word_id > 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joris/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# Function that determines the average vector of a test\n",
    "# INPUT\n",
    "# - a list of strings, for instance ['python','wizard']\n",
    "# - a word_vectors model\n",
    "# RETURNS\n",
    "# - a vector of size 100\n",
    "def get_average_vector(text,word_vectors):\n",
    "    \n",
    "    if len(text) == 0: # if the document is empty\n",
    "        return np.zeros(100)\n",
    "    \n",
    "    average = 0\n",
    "    for i in range(0,len(text)):\n",
    "        if i == 0:\n",
    "            average = copy.copy(get_vector_for_word(text[i],word_vectors))\n",
    "        else:\n",
    "            average += copy.copy(get_vector_for_word(text[i],word_vectors))\n",
    "    return average/len(text)  \n",
    "\n",
    "# Calculate the average word vector of document in the colletion\n",
    "# This is a preprocessing step\n",
    "# It returns a dict where dict[1] returns the average word vector of document 1\n",
    "def get_doc2vec():\n",
    "    doc2vec = {}\n",
    "\n",
    "    for i in range(1,num_documents+1):\n",
    "        doc_i = get_document(int2ext_ids[i])[:20]\n",
    "                \n",
    "        average_doc_vec = get_average_vector(doc_i,word_vectors)\n",
    "\n",
    "        doc2vec[i] = average_doc_vec\n",
    "    return doc2vec  \n",
    "\n",
    "# Function that saves the doc2vec dictionary to a pickle file\n",
    "def save_doc2vec():\n",
    "    doc2vec = get_doc2vec()\n",
    "    with open('doc2vec/doc2vec_dict.pickle', 'wb') as handle:\n",
    "            pickle.dump(doc2vec, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return\n",
    "\n",
    "# Function that loads the pickle doc2vec dictionary\n",
    "def load_doc2vec():\n",
    "    doc2vec = pickle.load(open('doc2vec/doc2vec_dict.pickle','rb'))\n",
    "    return doc2vec\n",
    "\n",
    "save_doc2vec()\n",
    "doc2vec = load_doc2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that calculates the top1000 document ranking for a query\n",
    "# INPUT\n",
    "# - a query id, 51,200 (integer)\n",
    "# - token2id, a dictionary of tokens to IDs\n",
    "# - word_vectors, a dictionary of word_vectors\n",
    "# RETURNS\n",
    "# - a list of the 1000 documents, a list of form [(APYYYYY-YY,scoreY),(APXXXXX-XX,scoreX),(etc,score_etc),...],\n",
    "# , where the first element of the list is the best query result, and the last element of the list is the worst \n",
    "def average_vector_scores(query_id,token2id,word_vectors):\n",
    "    query = remove_punctuation(queries[str(query_id)].split(),token2id)\n",
    "    query_vec = get_average_vector(query,word_vectors)\n",
    "    \n",
    "    ranking = []\n",
    "    \n",
    "    for i in range(1,num_documents+1):\n",
    "        ext_doc_ID = int2ext_ids[i]\n",
    "        average_doc_vec = doc2vec[i]\n",
    "\n",
    "        score = ssd.cosine(query_vec,average_doc_vec)\n",
    "\n",
    "        ranking.append((ext_doc_ID,score))\n",
    "    \n",
    "    ranking.sort(key=itemgetter(1))\n",
    "    \n",
    "    return ranking[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joris/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/joris/miniconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "def vector_average_main(model_name):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for query_id in valid_query_ids:\n",
    "        ranking = average_vector_scores(query_id,token2id,word_vectors)\n",
    "        \n",
    "        data = append_data(ranking,int(query_id),model_name,data)\n",
    "            \n",
    "    write_model(model_name,data)\n",
    "    shutil.move('./'+model_name,'./trec_eval/'+model_name)\n",
    "    \n",
    "vector_average_main('AV20.run')\n",
    "write_results('AV20')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top1000(query_ids):\n",
    "    #First we get the top 1000 documents for every query\n",
    "    top1000_dict = {}\n",
    "\n",
    "    for query_id in query_ids:\n",
    "        tfidf_dict = {}\n",
    "        query_ids = [token2id.get(query_token,0) for query_token in index.tokenize(queries[query_id])] #get ids for all the words\n",
    "        query_ids = [word_id for word_id in query_ids if word_id > 0] #remove stop words\n",
    "        for int_document_id in range(index.document_base(), index.maximum_document()):\n",
    "            tfidf_score = 0\n",
    "            for term_id in query_ids:\n",
    "                if int_document_id in inverted_index[term_id].keys():\n",
    "                    tfidf_score += tfidf(int_document_id, term_id, collection_frequencies[term_id])\n",
    "                else:\n",
    "                    tfidf_score += 0.0\n",
    "            tfidf_dict[int_document_id] = tfidf_score\n",
    "\n",
    "        top1000 = sorted(tfidf_dict.items(), key=lambda x:-x[1])[:1000]\n",
    "        top1000_keys = [i[0] for i in top1000]\n",
    "        top1000_dict[query_id] = top1000_keys\n",
    "\n",
    "    return top1000_dict\n",
    "\n",
    "def word2vec_most_common_words(query):\n",
    "    start = time.time()\n",
    "    query_words = query.split()\n",
    "    query_words = remove_punctuation(query_words,token2id)\n",
    "    scores = []\n",
    "    query_matrix = np.zeros((len(query_words),100))\n",
    "    for i in range(0,len(query_words)):\n",
    "        try:\n",
    "            query_matrix[i] = get_vector_for_word(query_words[i],word_vectors)\n",
    "        except:\n",
    "            print(query_words[i])\n",
    "            query_matrix[i] = [0 for i in range(0,100)] #Since word vector are trained using documents we can have new words here\n",
    "    for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "        new_dict = {}\n",
    "        _, doc_token_ids = index.document(int_doc_id)\n",
    "\n",
    "        doc_counter = dict(Counter(doc_token_ids))\n",
    "\n",
    "        relevant_word_ids = dict(Counter(doc_counter).most_common(10))\n",
    "\n",
    "        if 0 in relevant_word_ids.keys():\n",
    "            del relevant_word_ids[0]\n",
    "\n",
    "        doc_words = []\n",
    "        for i in relevant_word_ids:\n",
    "            doc_words.append(id2token[i])\n",
    "\n",
    "        doc_matrix = np.zeros((len(doc_words),100))\n",
    "        for i in range(0,len(doc_words)):\n",
    "            doc_matrix[i] = get_vector_for_word(doc_words[i],word_vectors)\n",
    "\n",
    "        scores.append(np.sum(np.dot(query_matrix,doc_matrix.T))/(len(query_words)))\n",
    "    print(\"Elapsed time for \", query, \" is: \", time.time() - start)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def word2vec_best_documents(query,query_id,query_dict):\n",
    "    start = time.time()\n",
    "    query_words = query.split()\n",
    "    query_words = remove_punctuation(query_words,token2id)\n",
    "    scores = []\n",
    "    query_matrix = np.zeros((len(query_words),100))\n",
    "    for i in range(0,len(query_words)):\n",
    "        try:\n",
    "            query_matrix[i] = get_vector_for_word(query_words[i],word_vectors)\n",
    "        except: #Since word vector are trained using documents we can have new words here\n",
    "            print(query_words[i])\n",
    "            query_matrix[i] = [0 for i in range(0,100)]\n",
    "\n",
    "    for int_doc_id in query_dict[query_id]:\n",
    "        _, doc_token_ids = index.document(int_doc_id)\n",
    "        doc_words = []\n",
    "\n",
    "        doc_counter = dict(Counter(doc_token_ids))\n",
    "\n",
    "        relevant_word_ids = dict(Counter(doc_counter).most_common(30))\n",
    "\n",
    "        if 0 in relevant_word_ids.keys():\n",
    "            del relevant_word_ids[0]\n",
    "\n",
    "        doc_words = []\n",
    "        for i in relevant_word_ids:\n",
    "            doc_words.append(id2token[i])\n",
    "\n",
    "        doc_matrix = np.zeros((len(doc_words),100))\n",
    "        for i in range(0,len(doc_words)):\n",
    "            doc_matrix[i] = get_vector_for_word(doc_words[i],word_vectors)\n",
    "\n",
    "        scores.append(np.sum(np.dot(query_matrix,doc_matrix.T))/(len(query_words)))\n",
    "    print(\"Elapsed time for \", query_id, \" is: \", time.time() - start)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_queries = {}\n",
    "query_ids = []\n",
    "for query_id, query_text in queries.items():\n",
    "    if query_id in valid_query_ids:\n",
    "        query_ids.append(query_id)\n",
    "        validation_queries[query_id] = query_text\n",
    "        \n",
    "query_1000_dict = top1000(query_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2vec_retrieval1():\n",
    "    data = {}\n",
    "    for query_id, query in validation_queries.items():\n",
    "        if query_id in valid_query_ids:\n",
    "            scores = word2vec_most_common_words(query)\n",
    "            for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "                external_document_id,_ = index.document(int_doc_id)\n",
    "\n",
    "                if query_id in data.keys():\n",
    "                    data[query_id].append((tuple([float(scores[int_doc_id-1]),str(external_document_id)])))\n",
    "                else:\n",
    "                    data[query_id] = [((tuple([float(scores[int_doc_id-1]),str(external_document_id)])))]\n",
    "    run_out_path = '{}.run'.format('word2vec_advanced1')\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name='word2vec_advanced1',\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "\n",
    "def word2vec_retrieval2():\n",
    "    data = {}\n",
    "    for key,value in validation_queries.items():\n",
    "        scores = word2vec_best_documents(validation_queries[key],key,query_1000_dict)\n",
    "        external_doc_ids = []\n",
    "        for int_doc_id in query_1000_dict[key]:\n",
    "            external_document_id,_ = index.document(int_doc_id)\n",
    "            external_doc_ids.append(external_document_id)\n",
    "\n",
    "        assert(len(scores) == len(external_doc_ids))\n",
    "\n",
    "        for i in range(0,len(scores)):\n",
    "            if key in data.keys():\n",
    "                data[key].append((tuple([float(scores[i]),str(external_doc_ids[i])])))\n",
    "            else:\n",
    "                data[key] =[((tuple([float(scores[i]),str(external_doc_ids[i])])))]\n",
    "\n",
    "    run_out_path = '{}.run'.format('word2vec_advanced3')\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name='word2vec_advanced3',\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for  Computer-aided Crime  is:  57.88444113731384\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-977beec424b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword2vec_retrieval1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mword2vec_retrieval2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-d9c69878329e>\u001b[0m in \u001b[0;36mword2vec_retrieval1\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_queries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_query_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec_most_common_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mint_doc_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mexternal_document_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_doc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-2742c0f46605>\u001b[0m in \u001b[0;36mword2vec_most_common_words\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_token_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_doc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mdoc_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_token_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mrelevant_word_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word2vec_retrieval1()\n",
    "word2vec_retrieval2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Learning to rank (LTR) [15 points] (open-ended) ###\n",
    "\n",
    "In this task you will get an introduction into learning to rank for information retrieval.\n",
    "\n",
    "You can explore different ways for devising features for the model. Obviously, you can use the retrieval methods you implemented in Task 1, Task 2 and Task 3 as features. Think about other features you can use (e.g. query/document length). Creativity on devising new features and providing motivation for them will be taken into account when grading.\n",
    "\n",
    "For every query, first create a document candidate set using the top-1000 documents using TF-IDF, and subsequently compute features given a query and a document. Note that the feature values of different retrieval methods are likely to be distributed differently.\n",
    "\n",
    "You are adviced to start some pointwise learning to rank algorithm e.g. logistic regression, implemented in [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "Train your LTR model using 10-fold cross validation on the test set. More advanced learning to rank algorithms will be appreciated when grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27039, 121400, 80889, 61237, 156344, 149653, 70671, 69264, 5480, 91382]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor query_id in test_query_ids:\\n    tfidf_dict = {}\\n    query_ids = [token2id.get(query_token,0) for query_token in index.tokenize(queries[query_id])] #get ids for all the words\\n    query_ids = [word_id for word_id in query_ids if word_id > 0] #remove stop words\\n    for int_document_id in range(index.document_base(), index.maximum_document()):\\n        tfidf_score = 0\\n        for term_id in query_ids:\\n            if int_document_id in inverted_index[term_id].keys():\\n                tfidf_score += tfidf(int_document_id, term_id, collection_frequencies[term_id])\\n            else: \\n                tfidf_score += 0.0\\n        tfidf_dict[int_document_id] = tfidf_score\\n    top1000 = sorted(tfidf_dict.items(), key=lambda x:-x[1])[:1000]\\n    top1000_keys = [i[0] for i in top1000]\\n    top1000_dict[query_id] = top1000_keys\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we get the top 1000 documents for every query\n",
    "top1000_dict = top1000(test_query_ids)\n",
    "print(top1000_dict['68'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following statistics per document, query pair:\n",
    "-Number of words of document. Rationale: long documents tend to be more relevant than short documents.\n",
    "\n",
    "-Number of word in query. Rationale: long/short queries might have different type of relevant results.\n",
    "\n",
    "-Percentage of stop words. Rationale: if the text contains a lot of stop words it might be written badly or does not contain interesting words.\n",
    "\n",
    "-Amount of unique words. Rationale: if the amount of unique words is large, the document might be very broad and covers multiple topics?\n",
    "\n",
    "-Word count statistics: mean normalized word count, variance of normalized word count. A high mean word count means the document is very dense on a small amount of words, which might be very in depth about a topic. A low mean can have a high or low variance, if the variance is high there are a lot of words with low counts and only a couple with high counts. This might add more information of the document. \n",
    "\n",
    "-Scores of methods from other questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In this cell, we get some statistics + previous scores on the documents\n",
    "\n",
    "#Number of words \n",
    "def number_of_words(int_document_id):\n",
    "    return len(index.document(int_document_id)[1])\n",
    "\n",
    "#Number of query words\n",
    "def number_of_query_words(query_id):\n",
    "    return len([token2id.get(query_token,0) for query_token in index.tokenize(queries[query_id])])\n",
    "\n",
    "#Percentage of stop words:\n",
    "def perc_stop_words(int_document_id):\n",
    "    return len([i for i in index.document(int_document_id)[1] if i == 0])/len(index.document(int_document_id)[1])\n",
    "\n",
    "#Amount of different non stop words\n",
    "def amount_of_words(int_document_id):\n",
    "    return len(np.unique(index.document(int_document_id)[1]))\n",
    "\n",
    "#Distribution of word counts\n",
    "def word_count_statistics(int_document_id):\n",
    "    counter = Counter(index.document(int_document_id)[1]) #make a counter dict\n",
    "    total = sum(counter.values())\n",
    "    for key in counter: #we normalize the counts\n",
    "        counter[key] /= total \n",
    "    return np.mean(list(counter.values())), np.var(list(counter.values()))\n",
    "    \n",
    "def get_scores(int_document_id, query_id):\n",
    "    scores = []\n",
    "    query_ids = [token2id.get(query_token,0) for query_token in index.tokenize(queries[query_id])] #get ids for all the words\n",
    "    query_ids = [word_id for word_id in query_ids if word_id > 0] #remove stop words\n",
    "    scores.append(JelinekMercer(int_document_id, query_ids, collection_frequencies))\n",
    "    scores.append(Dirichlet(int_document_id, query_ids, collection_frequencies))\n",
    "    scores.append(AbsoluteDiscounting(int_document_id, query_ids, collection_frequencies))\n",
    "    \n",
    "    tfidf_score = 0\n",
    "    bm25_score = 0\n",
    "    for query_id in query_ids:\n",
    "        if int_document_id in inverted_index[query_id].keys():\n",
    "            tfidf_score += tfidf(int_document_id, query_id, collection_frequencies[query_id])\n",
    "            bm25_score += BM25(int_document_id, query_id, collection_frequencies[query_id])\n",
    "        else: \n",
    "            tfidf_score += 0.0\n",
    "            bm25_score += 0.0\n",
    "    scores.append(tfidf_score)\n",
    "    scores.append(bm25_score)      \n",
    "    scores.append(plm(int_document_id, query_ids, \"Gaussian\", collection_frequencies, 0))\n",
    "    scores.append(plm(int_document_id, query_ids, \"Passage\", collection_frequencies, 0))\n",
    "    scores.append(plm(int_document_id, query_ids, \"Circle\", collection_frequencies, 0))\n",
    "    scores.append(plm(int_document_id, query_ids, \"Triangle\", collection_frequencies, 0))\n",
    "    scores.append(plm(int_document_id, query_ids, \"Hamming\", collection_frequencies, 0))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "61\n",
      "101\n",
      "142\n",
      "176\n",
      "82\n",
      "106\n",
      "163\n",
      "199\n",
      "137\n",
      "153\n",
      "184\n",
      "146\n",
      "91\n",
      "186\n",
      "200\n",
      "149\n",
      "198\n",
      "131\n",
      "72\n",
      "171\n",
      "152\n",
      "183\n",
      "161\n",
      "81\n",
      "187\n",
      "97\n",
      "122\n",
      "169\n",
      "197\n",
      "66\n",
      "105\n",
      "80\n",
      "65\n",
      "177\n",
      "88\n",
      "160\n",
      "115\n",
      "83\n",
      "52\n",
      "70\n",
      "79\n",
      "141\n",
      "117\n",
      "124\n",
      "84\n",
      "178\n",
      "136\n",
      "172\n",
      "185\n",
      "134\n",
      "145\n",
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "166\n",
      "98\n",
      "128\n",
      "130\n",
      "85\n",
      "75\n",
      "60\n",
      "147\n",
      "107\n",
      "108\n",
      "133\n",
      "100\n",
      "139\n",
      "162\n",
      "189\n",
      "102\n",
      "118\n",
      "55\n",
      "51\n",
      "63\n",
      "96\n",
      "119\n",
      "129\n",
      "188\n",
      "125\n",
      "157\n",
      "164\n",
      "56\n",
      "174\n",
      "148\n",
      "154\n",
      "59\n",
      "138\n",
      "58\n",
      "194\n",
      "112\n",
      "126\n",
      "190\n",
      "99\n",
      "116\n",
      "121\n",
      "71\n",
      "54\n",
      "175\n",
      "168\n",
      "191\n",
      "110\n",
      "87\n",
      "64\n",
      "159\n",
      "193\n",
      "77\n",
      "62\n",
      "132\n",
      "179\n",
      "127\n",
      "67\n",
      "104\n",
      "156\n",
      "73\n",
      "195\n",
      "150\n",
      "196\n",
      "181\n",
      "109\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "#Now we create a large matrix with all statistics on the documents.\n",
    "def get_details(int_document_id, query_id):\n",
    "    detail = []\n",
    "    detail.append(number_of_words(int_document_id))\n",
    "    detail.append(perc_stop_words(int_document_id))\n",
    "    detail.append(amount_of_words(int_document_id))\n",
    "    [detail.append(i) for i in word_count_statistics(int_document_id)]\n",
    "    [detail.append(i) for i in get_scores(int_document_id, query_id)]\n",
    "    return detail\n",
    "details = np.zeros((1000*len(test_query_ids), len(get_details(1, query_id)))) #define an empty matrix\n",
    "\n",
    "for q in range(0, len(test_query_ids)):\n",
    "    query_id = test_query_ids[q]\n",
    "    print(query_id)\n",
    "    for key in range(0, 1000):\n",
    "        detail = get_details(top1000_dict[query_id][key], query_id)\n",
    "        for d in range(0,len(detail)):\n",
    "            if np.isnan(detail[d]) or detail[d] > 100000: #sometimes there is a nan value, probably a document being length 0\n",
    "                details[q*1000+key, d] = 0\n",
    "            else:\n",
    "                details[q*1000+key, d] = detail[d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As every measure has a different scale, we will normalize the data between 0-1 to have nice features for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(details.shape)\n",
    "#details_not_nan = details[~np.isnan(details)] #there was 1 nan value. Probably a document being length 0.\n",
    "#print(details.shape)\n",
    "details = (details - details.min(axis=0)) / (details.max(axis=0) - details.min(axis=0)) #normalize columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by doing pointwise learning so we can treat the document ratings as targets. This way the problems becomes a regression problem. First we will generate target, then we will implement a wide range of models to slove the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we generate target from the qrel_test file\n",
    "target_dict = {}\n",
    "with open('./ap_88_89/qrel_test', 'r') as test_queries:\n",
    "    for line in test_queries:\n",
    "        split = line.split(' ')\n",
    "        query_doc_tuple = (split[0], split[2])\n",
    "        target_dict[query_doc_tuple] = int(split[3][0])\n",
    "\n",
    "targets = np.zeros(1000*len(test_query_ids)) #define an empty target array        \n",
    "for q in range(0, len(test_query_ids)):\n",
    "    query_id = test_query_ids[q]\n",
    "    for key in range(0,1000):\n",
    "        external_document_id,_ = index.document(top1000_dict[query_id][key])\n",
    "        try:\n",
    "            targets[q*1000+key] = target_dict[(query_id, external_document_id)]\n",
    "        except:\n",
    "            targets[q*1000+key] = 0 #if targets do not exist in the test set, we assume they are irrelevant\n",
    "#print(targets[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for a single CV split is:  0.9534166666666667\n",
      "The accuracy score for a single CV split is:  0.9466666666666667\n",
      "The accuracy score for a single CV split is:  0.971\n",
      "The accuracy score for a single CV split is:  0.9489166666666666\n",
      "The accuracy score for a single CV split is:  0.9375\n",
      "The accuracy score for a single CV split is:  0.9294166666666667\n",
      "The accuracy score for a single CV split is:  0.9351666666666667\n",
      "The accuracy score for a single CV split is:  0.92075\n",
      "The accuracy score for a single CV split is:  0.9229166666666667\n",
      "The accuracy score for a single CV split is:  0.94575\n",
      "The overall accuracy score is:  0.94115\n"
     ]
    }
   ],
   "source": [
    "#The first model will be a LogisticRegression\n",
    "predictions1 = np.zeros(1000*len(test_query_ids))\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(details):\n",
    "    X_train, X_test = details[train_index], details[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    predictions1[test_index] = lr.predict(X_test)\n",
    "    print(\"The accuracy score for a single CV split is: \", lr.score(X_test, y_test))\n",
    "    \n",
    "overall_score = sum([1 for i in range(0,1000*len(test_query_ids)) if targets[i] == predictions1[i]])/(1000*len(test_query_ids))\n",
    "print(\"The overall accuracy score is: \",overall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. A 94% accuracy looks quite good. However when testing the results in trec_eval, the results are quite bad (map 0.0717, P_5\t0.1333, recall_1000 0.6432, ndcg_cut_10 0.1285). This is due to the low amount of 1's, therefore the algorithm predicts almost only 0s. This makes the accuracy very high, but the relevancy very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  7007  interesting documents!\n",
      "This is  5.839166666666666 % of the selected documents!\n",
      "We have  409  non zero predictions!\n"
     ]
    }
   ],
   "source": [
    "print(\"We have \",sum([1 for i in targets if i ==1]),\" interesting documents!\")\n",
    "print(\"This is \",sum([1 for i in targets if i ==1])/1200,\"% of the selected documents!\")\n",
    "print(\"We have \",sum([1 for i in predictions1 if i ==1]),\" non zero predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for a single CV split is:  0.88275\n",
      "The accuracy score for a single CV split is:  0.9083333333333333\n",
      "The accuracy score for a single CV split is:  0.9504166666666667\n",
      "The accuracy score for a single CV split is:  0.9426666666666667\n",
      "The accuracy score for a single CV split is:  0.92925\n",
      "The accuracy score for a single CV split is:  0.8940833333333333\n",
      "The accuracy score for a single CV split is:  0.9331666666666667\n",
      "The accuracy score for a single CV split is:  0.9096666666666666\n",
      "The accuracy score for a single CV split is:  0.912\n",
      "The accuracy score for a single CV split is:  0.878\n",
      "The overall accuracy score is:  0.9140333333333334\n",
      "We have  6275  non zero predictions!\n"
     ]
    }
   ],
   "source": [
    "#This is a Logistic Regression including class weights, as the classes are not evenly distributed and 1s are more important for our purpose.\n",
    "predictions2 = np.zeros(1000*len(test_query_ids))\n",
    "proba2 = np.zeros((1000*len(test_query_ids),2))\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(details):\n",
    "    X_train, X_test = details[train_index], details[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "    lr = LogisticRegression(class_weight={1:0.85, 0:0.15}) #we add class weights to weigh more heavy on predicting 1.\n",
    "    lr.fit(X_train, y_train)\n",
    "    predictions2[test_index] = lr.predict(X_test)\n",
    "    proba2[test_index] = lr.predict_proba(X_test)                   \n",
    "    print(\"The accuracy score for a single CV split is: \", lr.score(X_test, y_test))\n",
    "    \n",
    "overall_score = sum([1 for i in range(0,1000*len(test_query_ids)) if targets[i] == predictions2[i]])/(1000*len(test_query_ids))\n",
    "print(\"The overall accuracy score is: \",overall_score)\n",
    "print(\"We have \",sum([1 for i in predictions2 if i ==1]),\" non zero predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did is that we added the class weight, to count 1s more heavily in the scoring. We can see that with ~6000 predictions, the model more closely predicts the total amount of relevant docs (~7000). Although this drops the accuracy score from 94% to 91%, the trec_eval measures improve significantly (map 0.1231, P_5 0.2800, recall_1000  0.6432 and ndcg_cut_10 0.2847)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the first 20 predictions:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "These are the first 20 confindences:  [0.7401585168289526, 0.6238643775653643, 0.585274962655717, 0.6874234497182934, 0.6472259474996357, 0.5097211079085744, 0.6266523251043203, 0.6282685696292994, 0.4682124718707086, 0.49573119149075157, 0.5876897993961567, 0.4730741594600038, 0.4608665836231617, 0.4445035308400285, 0.5024350527639426, 0.39128550636904164, 0.42727680718605027, 0.4679859657206905, 0.43472639312240136, 0.539722137680394]\n",
      "\n",
      "The positive predictions range between:  0.5024350527639426  and  0.7401585168289526  so there is quite some difference in prediction certainty.\n"
     ]
    }
   ],
   "source": [
    "print(\"These are the first 20 predictions: \", list(predictions2[:20]))\n",
    "print(\"These are the first 20 confindences: \", list(proba2[:20,1]))\n",
    "pos_proba = [i for i in proba2[:20,1] if i > 0.5]\n",
    "print(\"\")\n",
    "print(\"The positive predictions range between: \",min(pos_proba),\" and \",max(pos_proba),\" so there is quite some difference in prediction certainty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another issue is that every prediction is either 0/1, however LogisticRegression maps a value between 0-1 to a group. However we can use the confidence of being in class 1 of the LogisticRegression to score documents. This results in a significantly better scoring on trec_eval measures: map\t0.2103, P_5\t0.3967, recall_1000\t0.6432 and ndcg_cut_10 0.3868."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network + More features\n",
    "Besides the scoring of the previous models, we also want to add the complete tfidf matrix for all terms used in queries. Furthermore we will use a neural network for predicting the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  456  distinct query tokens.\n",
      "Making doc tfidf\n",
      "Making query tfidf\n"
     ]
    }
   ],
   "source": [
    "#Now we want to develop tf-idf for all documents and queries only for the query tokens (we cannot handle 270K tokens for now).\n",
    "unique_query_tokens = {}\n",
    "for query_id, query in queries.items():\n",
    "    query_word_ids = [token2id.get(query_token,0) for query_token in index.tokenize(query)] #get ids for all the words\n",
    "    query_word_ids = [word_id for word_id in query_word_ids if word_id > 0] #remove stop words\n",
    "    for t in query_word_ids:\n",
    "        unique_query_tokens[t] = 1\n",
    "query_keys = list(unique_query_tokens.keys())\n",
    "print(\"We have \",len(query_keys),\" distinct query tokens.\")\n",
    "\n",
    "tfidf_docs = np.zeros((index.maximum_document(), len(query_keys)))\n",
    "print(\"Making doc tfidf\")\n",
    "for query_term in query_keys:\n",
    "    idx = query_keys.index(query_term)\n",
    "    col_freq = collection_frequencies[query_term]\n",
    "    num_documents = index.maximum_document()\n",
    "    for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "        try:\n",
    "            tfidf_docs[int_doc_id, idx] = float(np.log(1+inverted_index[query_term][int_document_id]) * np.log(num_documents/col_freq))\n",
    "        except:\n",
    "            tfidf_docs[int_doc_id, idx] = 0\n",
    "\n",
    "print(\"Making query tfidf\")\n",
    "tfidf_queries = np.zeros((len(test_query_ids), len(query_keys)))\n",
    "for query_term in query_keys:\n",
    "    idx = query_keys.index(query_term)\n",
    "    col_freq = collection_frequencies[query_term]\n",
    "    num_documents = index.maximum_document()\n",
    "    for q in range(0, len(test_query_ids)):\n",
    "        query_words = [token2id.get(query_token,0) for query_token in index.tokenize(queries[test_query_ids[q]])]\n",
    "        tf = sum([1 for i in query_words if i == query_term])\n",
    "        try:\n",
    "            tfidf_queries[q, idx] = float(np.log(1+tf) * np.log(num_documents/col_freq))\n",
    "        except:\n",
    "            tfidf_queries[q, idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 927)\n"
     ]
    }
   ],
   "source": [
    "#Here we generate the details_tfidf matrix which puts all the documents and query tfidf in place.\n",
    "details_tfidf = np.zeros((120000, len(query_keys)*2))\n",
    "for q in range(0, len(test_query_ids)):\n",
    "    query_id = test_query_ids[q]\n",
    "    top1000_idx = top1000_dict[query_id]\n",
    "    details_tfidf[q*1000:(q+1)*1000, :len(query_keys)] = tfidf_docs[top1000_idx,:]\n",
    "    for j in range(0,1000):\n",
    "        details_tfidf[q*1000+j, len(query_keys):] = tfidf_queries[q,:]\n",
    "details_full = np.concatenate((details, details_tfidf), axis=1)\n",
    "print(details_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 19s 173us/step - loss: 0.1911\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 17s 162us/step - loss: 0.1777\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 17s 162us/step - loss: 0.1728\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 17s 161us/step - loss: 0.1698\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 17s 161us/step - loss: 0.1676\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 17s 161us/step - loss: 0.1656\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 17s 162us/step - loss: 0.1643\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 17s 161us/step - loss: 0.1629\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 17s 161us/step - loss: 0.1619\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 17s 162us/step - loss: 0.1607\n",
      "12000/12000 [==============================] - 1s 48us/step\n",
      "0.2632309768696626\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 19s 179us/step - loss: 0.1920\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 18s 163us/step - loss: 0.1779\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 18s 162us/step - loss: 0.1732\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 18s 168us/step - loss: 0.1698\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 19s 173us/step - loss: 0.1675\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 18s 169us/step - loss: 0.1657\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 18s 170us/step - loss: 0.1644\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 18s 170us/step - loss: 0.1634\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 18s 171us/step - loss: 0.1620\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 18s 171us/step - loss: 0.1606\n",
      "12000/12000 [==============================] - 1s 50us/step\n",
      "0.25869467310545347\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 19s 175us/step - loss: 0.1977\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 19s 173us/step - loss: 0.1815\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 19s 173us/step - loss: 0.1764\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 19s 179us/step - loss: 0.1730\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1707\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 19s 177us/step - loss: 0.1686\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 19s 177us/step - loss: 0.1674\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 19s 177us/step - loss: 0.1663\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 19s 176us/step - loss: 0.1653\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 19s 177us/step - loss: 0.1640\n",
      "12000/12000 [==============================] - 1s 54us/step\n",
      "0.31422511642985046\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 19s 180us/step - loss: 0.1911\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 19s 179us/step - loss: 0.1768\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1723\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1688\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1664\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1653\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 19s 179us/step - loss: 0.1639\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 19s 177us/step - loss: 0.1630\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1626\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1617\n",
      "12000/12000 [==============================] - 1s 53us/step\n",
      "0.17639734058082104\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 20s 181us/step - loss: 0.1903\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 20s 186us/step - loss: 0.1756\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 20s 188us/step - loss: 0.1708\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 18s 170us/step - loss: 0.1675\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 14s 132us/step - loss: 0.1655\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 14s 131us/step - loss: 0.1640\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 14s 129us/step - loss: 0.1629\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 14s 129us/step - loss: 0.1614\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 14s 129us/step - loss: 0.1608\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 14s 129us/step - loss: 0.1594\n",
      "12000/12000 [==============================] - 0s 37us/step\n",
      "0.22072229270637037\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 14s 132us/step - loss: 0.1880\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1724\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1676\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1646\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1621\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1603\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 14s 129us/step - loss: 0.1586\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1574\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1562\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1556\n",
      "12000/12000 [==============================] - 0s 37us/step\n",
      "0.28744723014657697\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 14s 132us/step - loss: 0.1886\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1742\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1692\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 14s 130us/step - loss: 0.1665\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 18s 170us/step - loss: 0.1640\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 19s 177us/step - loss: 0.1626\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 19s 179us/step - loss: 0.1608\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1598\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 19s 180us/step - loss: 0.1589\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 18s 171us/step - loss: 0.1578\n",
      "12000/12000 [==============================] - 1s 55us/step\n",
      "0.26792655439302326\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1849\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 19s 173us/step - loss: 0.1692\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 19s 172us/step - loss: 0.1639\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 18s 171us/step - loss: 0.1610\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 19s 172us/step - loss: 0.1587\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 19s 172us/step - loss: 0.1567\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 19s 171us/step - loss: 0.1556\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 19s 172us/step - loss: 0.1539\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 19s 172us/step - loss: 0.1527\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 19s 172us/step - loss: 0.1519\n",
      "12000/12000 [==============================] - 1s 54us/step\n",
      "0.27663793893158434\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 19s 176us/step - loss: 0.1828\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 19s 173us/step - loss: 0.1691\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 19s 173us/step - loss: 0.1649\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 18s 165us/step - loss: 0.1617\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 18s 165us/step - loss: 0.1600\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1586\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1577\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1562\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1553\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 18s 165us/step - loss: 0.1542\n",
      "12000/12000 [==============================] - 1s 53us/step\n",
      "0.36457292728871105\n",
      "Epoch 1/10\n",
      "108000/108000 [==============================] - 18s 168us/step - loss: 0.1924\n",
      "Epoch 2/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1763\n",
      "Epoch 3/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1719\n",
      "Epoch 4/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1685\n",
      "Epoch 5/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1662\n",
      "Epoch 6/10\n",
      "108000/108000 [==============================] - 18s 165us/step - loss: 0.1645\n",
      "Epoch 7/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1629\n",
      "Epoch 8/10\n",
      "108000/108000 [==============================] - 18s 165us/step - loss: 0.1612\n",
      "Epoch 9/10\n",
      "108000/108000 [==============================] - 18s 166us/step - loss: 0.1604\n",
      "Epoch 10/10\n",
      "108000/108000 [==============================] - 18s 165us/step - loss: 0.1595\n",
      "12000/12000 [==============================] - 1s 54us/step\n",
      "0.25981026646991573\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "predictions_nn = np.zeros(1000*len(test_query_ids))\n",
    "\n",
    "def train_mlp(X_train,y_train,X_test,y_test):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=features,activation='sigmoid'))\n",
    "    #Add hidden layer\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    #Add output layer with 1 node to output between 0 and 1\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train, epochs=10, verbose=1)\n",
    "\n",
    "    # Final evaluation of the model\n",
    "    print(model.evaluate(x=X_test, y=y_test, batch_size=None, verbose=1))\n",
    "    predictions_nn[test_index] = model.predict(X_test).flatten()\n",
    "    \n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(details):\n",
    "    X_train, X_test = details_full[train_index], details_full[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "    train_mlp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although pointwise optimization of relevancy scores does not directly correlate directly with the trec eval measures, a simple neural network improves the performance of the ranking slightly in terms of ndcg: map 0.2133, P_5 0.4167, recall_1000 0.6432 and ndcg_cut_10 0.4066. The network seems to be overfitting sometimes (high loss difference between training and testing). Therefore we now try to add dropout and do less epochs to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 20s 185us/step - loss: 0.1911\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1772\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 19s 178us/step - loss: 0.1719\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 19s 179us/step - loss: 0.1697\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 19s 179us/step - loss: 0.1678\n",
      "12000/12000 [==============================] - 1s 69us/step\n",
      "0.3079065595964591\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 20s 186us/step - loss: 0.1910\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 20s 181us/step - loss: 0.1764\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 19s 180us/step - loss: 0.1721\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 19s 180us/step - loss: 0.1695\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 20s 185us/step - loss: 0.1682\n",
      "12000/12000 [==============================] - 1s 72us/step\n",
      "0.25785438568990987\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 20s 190us/step - loss: 0.1957\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 20s 184us/step - loss: 0.1800\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 20s 184us/step - loss: 0.1759\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 20s 184us/step - loss: 0.1732\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 20s 185us/step - loss: 0.1709\n",
      "12000/12000 [==============================] - 1s 72us/step\n",
      "0.2664776547161552\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 21s 191us/step - loss: 0.1909\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 20s 185us/step - loss: 0.1761\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 20s 186us/step - loss: 0.1725\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 20s 187us/step - loss: 0.1691\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 20s 187us/step - loss: 0.1677\n",
      "12000/12000 [==============================] - 1s 73us/step\n",
      "0.27429977810879547\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 21s 192us/step - loss: 0.1889\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 20s 187us/step - loss: 0.1745\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 20s 187us/step - loss: 0.1700\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 21s 197us/step - loss: 0.1682\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 21s 193us/step - loss: 0.1659\n",
      "12000/12000 [==============================] - 1s 77us/step\n",
      "0.269803019930919\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 21s 199us/step - loss: 0.1865\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 21s 197us/step - loss: 0.1711\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 21s 193us/step - loss: 0.1666\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 21s 194us/step - loss: 0.1641\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 21s 196us/step - loss: 0.1623\n",
      "12000/12000 [==============================] - 1s 80us/step\n",
      "0.2979630815287431\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 18s 169us/step - loss: 0.1870\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 18s 171us/step - loss: 0.1730\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 16s 147us/step - loss: 0.1689\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 15s 140us/step - loss: 0.1667\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 15s 140us/step - loss: 0.1646\n",
      "12000/12000 [==============================] - 1s 59us/step\n",
      "0.30306976586580275\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 16s 147us/step - loss: 0.1828\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 15s 141us/step - loss: 0.1677\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 16s 147us/step - loss: 0.1633\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 16s 147us/step - loss: 0.1610\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 17s 156us/step - loss: 0.1588\n",
      "12000/12000 [==============================] - 1s 60us/step\n",
      "0.4265035261809826\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 26s 238us/step - loss: 0.1829\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 16s 145us/step - loss: 0.1692\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 21s 194us/step - loss: 0.1649\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 21s 193us/step - loss: 0.1624\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 21s 193us/step - loss: 0.1608\n",
      "12000/12000 [==============================] - 1s 80us/step\n",
      "0.31081696366270384\n",
      "Epoch 1/5\n",
      "108000/108000 [==============================] - 22s 200us/step - loss: 0.1902\n",
      "Epoch 2/5\n",
      "108000/108000 [==============================] - 21s 197us/step - loss: 0.1754\n",
      "Epoch 3/5\n",
      "108000/108000 [==============================] - 17s 162us/step - loss: 0.1710\n",
      "Epoch 4/5\n",
      "108000/108000 [==============================] - 21s 190us/step - loss: 0.1683\n",
      "Epoch 5/5\n",
      "108000/108000 [==============================] - 21s 196us/step - loss: 0.1658\n",
      "12000/12000 [==============================] - 1s 87us/step\n",
      "0.26990819356404244\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "predictions_nn_dropout = np.zeros(1000*len(test_query_ids))\n",
    "\n",
    "def train_mlp_dropout(X_train,y_train,X_test,y_test):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=features,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    #Add hidden layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    #Add output layer with 1 node to output between 0 and 1\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train, epochs=5, verbose=1)\n",
    "\n",
    "    # Final evaluation of the model\n",
    "    print(model.evaluate(x=X_test, y=y_test, batch_size=None, verbose=1))\n",
    "    predictions_nn_dropout[test_index] = model.predict(X_test).flatten()\n",
    "    \n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(details):\n",
    "    X_train, X_test = details_full[train_index], details_full[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "    train_mlp_dropout(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout did not really improve the results: map 0.2084, P_5 0.4200, recall_1000 0.6432 and ndcg_cut_10 0.4049.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate run files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This cell can put the results of the models into the .run files for evaluation.\n",
    "data = {}\n",
    "model_name = 'neural_network_dropout'\n",
    "for q in range(0, len(test_query_ids)):\n",
    "    query_id = test_query_ids[q]\n",
    "    for key in range(0,1000):\n",
    "        external_document_id,_ = index.document(top1000_dict[query_id][key])\n",
    "        if query_id in data.keys():       \n",
    "            data[query_id].append((tuple([predictions_nn_dropout[q*1000+key],str(external_document_id)])))\n",
    "        else:\n",
    "            data[query_id] = [((tuple([predictions_nn_dropout[q*1000+key],str(external_document_id)])))]\n",
    "\n",
    "            \n",
    "run_out_path = '{}.run'.format(model_name)\n",
    "\n",
    "if os.path.exists(run_out_path):\n",
    "    print(\"File already exists\")\n",
    "else:\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 5: Write a report [15 points; instant FAIL if not provided] ###\n",
    "\n",
    "The report should be a PDF file created using the [sigconf ACM template](https://www.acm.org/publications/proceedings-template) and will determine a significant part of your grade.\n",
    "\n",
    "   * It should explain what you have implemented, motivate your experiments and detail what you expect to learn from them. **[10 points]**\n",
    "   * Lastly, provide a convincing analysis of your results and conclude the report accordingly. **[10 points]**\n",
    "      * Do all methods perform similarly on all queries? Why?\n",
    "      * Is there a single retrieval model that outperforms all other retrieval models (i.e., silver bullet)?\n",
    "      * ...\n",
    "\n",
    "**Hand in the report and your self-contained implementation source files.** Only send us the files that matter, organized in a well-documented zip/tgz file with clear instructions on how to reproduce your results. That is, we want to be able to regenerate all your results with minimal effort. You can assume that the index and ground-truth information is present in the same file structure as the one we have provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
